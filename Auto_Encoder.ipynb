{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peakutils in /home/ahaanbanerjee/anaconda3/envs/tensorflow/lib/python3.9/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy in /home/ahaanbanerjee/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from peakutils) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ahaanbanerjee/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from peakutils) (1.13.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install peakutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peakutils import baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Folder containing the spectroscopy files\n",
    "# folder_path = \"/media/ahaanbanerjee/Crucial X9/Capstone/dataset/\"\n",
    "\n",
    "# # Initialize an empty list to store all the dataframes\n",
    "# dataframes = []\n",
    "# all_wavenumbers = set()  # To store all unique wavenumbers\n",
    "# files = ['BLANK','PE','PMMA','PS','PTFE','PVC']\n",
    "# # Loop through all files in the folder\n",
    "# for pls in files:\n",
    "#     for file_name in os.listdir(folder_path+pls):\n",
    "#         if file_name.endswith(\".txt\"):  \n",
    "#             # Read each file into a DataFrame (space-separated values)\n",
    "#             file_path = os.path.join(folder_path, pls+'/'+file_name)\n",
    "#             data = pd.read_csv(file_path, sep = '\\s+', header=None, names=[\"wavenumber\", \"intensity\"])\n",
    "            \n",
    "#             # Truncate wavenumber values (round to nearest integer or truncate decimals)\n",
    "#             data[\"wavenumber\"] = data[\"wavenumber\"].round().astype(int)  # Adjust as needed\n",
    "            \n",
    "#             # Update the set of all wavenumbers\n",
    "#             all_wavenumbers.update(data[\"wavenumber\"].unique())\n",
    "            \n",
    "#             # Add file name and type columns\n",
    "#             data[\"file_name\"] = file_name\n",
    "#             data[\"type\"] = pls\n",
    "            \n",
    "#             # Append the DataFrame to the list\n",
    "#             dataframes.append(data)\n",
    "\n",
    "# # Sort the unique wavenumbers\n",
    "# all_wavenumbers = sorted(all_wavenumbers)\n",
    "\n",
    "# # Create the final combined DataFrame\n",
    "# final_data = pd.DataFrame(columns=[\"file_name\", \"type\"] + all_wavenumbers)\n",
    "\n",
    "# # Populate the final DataFrame\n",
    "# for df in dataframes:\n",
    "#     # Pivot the data so wavenumber becomes columns and intensity becomes the values\n",
    "#     pivoted = df.pivot_table(index=[\"file_name\", \"type\"], columns=\"wavenumber\", values=\"intensity\", aggfunc=\"first\")\n",
    "    \n",
    "#     # Reindex to ensure all wavenumbers are included, filling missing values with NaN\n",
    "#     pivoted = pivoted.reindex(columns=all_wavenumbers, fill_value=np.nan)\n",
    "    \n",
    "#     # Reset index and append to final DataFrame\n",
    "#     pivoted.reset_index(inplace=True)\n",
    "#     final_data = pd.concat([final_data, pivoted], ignore_index=True)\n",
    "\n",
    "# # Save the combined DataFrame to a CSV file\n",
    "# output_path = \"combined_spectroscopy_nano_plastic.csv\"\n",
    "# final_data.to_csv(output_path, index=False)\n",
    "\n",
    "# print(f\"Combined data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # Replace 'your_data_file.txt' with the path to your text file\n",
    "# data_file = '/media/ahaanbanerjee/Crucial X9/Capstone/Non _Baseline/sta-1.txt'\n",
    "# data_file2 = '/media/ahaanbanerjee/Crucial X9/Capstone/Baseline_Corrected/sta-1.txt'\n",
    "# # Read the data from the text file assuming it is space separated\n",
    "# data1 = pd.read_csv(data_file, sep='\\s+', header=None, names=['Raman Shift', 'Intensity'])\n",
    "# data2 = pd.read_csv(data_file2, sep='\\s+', header=None, names=['Raman Shift', 'Intensity'])\n",
    "# # Plot the data\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.plot(data1['Raman Shift'], data1['Intensity'], marker='', color='blue', linewidth=2)\n",
    "# plt.plot(data2['Raman Shift'], data2['Intensity'], marker='', color='red', linewidth=2)\n",
    "# plt.title('Raman Spectroscopy Data')\n",
    "# plt.xlabel('Raman Shift (cm-1)')\n",
    "# plt.ylabel('Intensity')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "all_input_data = []\n",
    "cnt = 0\n",
    "data = pd.read_csv(\"/media/ahaanbanerjee/Crucial X9/Capstone/Data/fullBinary_aug_baselineCorr.csv\")\n",
    "\n",
    "remove_classes = [\"PS\", \"PC\", \"NC\", \"/\", \"ABS\"]\n",
    "#Filter out rows where 'Plastic' is in remove_classes\n",
    "data = data[~data['Plastic'].isin(remove_classes)]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))  # Normalize between 0 and 1\n",
    "wave_numbers = data.columns[3:]\n",
    "spectra = data.iloc[:, 3:].astype(float)\n",
    "\n",
    "# Loop through all the files in the input folder\n",
    "for col in range(len(spectra)):\n",
    "    y = spectra.iloc[col].values.astype(float)\n",
    "    temp = y.reshape(-1, 1)\n",
    "    \n",
    "    # Normalize between 0 and 1\n",
    "    temp = scaler.fit_transform(temp)\n",
    "    \n",
    "    # Flatten to 1D and store\n",
    "    temp = temp.reshape(1, -1)\n",
    "    \n",
    "    # Append to the list\n",
    "    all_input_data.append(temp)\n",
    "    cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Plastic</th>\n",
       "      <th>class</th>\n",
       "      <th>200.0904693</th>\n",
       "      <th>202.9747514</th>\n",
       "      <th>205.8580216</th>\n",
       "      <th>208.7402807</th>\n",
       "      <th>211.6215296</th>\n",
       "      <th>214.501769</th>\n",
       "      <th>217.3809999</th>\n",
       "      <th>...</th>\n",
       "      <th>3478.533384</th>\n",
       "      <th>3480.437351</th>\n",
       "      <th>3482.340824</th>\n",
       "      <th>3484.243803</th>\n",
       "      <th>3486.146288</th>\n",
       "      <th>3488.048279</th>\n",
       "      <th>3489.949777</th>\n",
       "      <th>3491.850782</th>\n",
       "      <th>3493.751294</th>\n",
       "      <th>3495.651313</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sta-1</td>\n",
       "      <td>PE</td>\n",
       "      <td>S</td>\n",
       "      <td>481.320059</td>\n",
       "      <td>456.004779</td>\n",
       "      <td>466.690553</td>\n",
       "      <td>448.377381</td>\n",
       "      <td>455.065262</td>\n",
       "      <td>463.754197</td>\n",
       "      <td>452.444185</td>\n",
       "      <td>...</td>\n",
       "      <td>222.087126</td>\n",
       "      <td>242.249061</td>\n",
       "      <td>210.412050</td>\n",
       "      <td>151.576093</td>\n",
       "      <td>188.741190</td>\n",
       "      <td>244.907340</td>\n",
       "      <td>225.074543</td>\n",
       "      <td>171.242801</td>\n",
       "      <td>188.412112</td>\n",
       "      <td>166.582477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sta-1</td>\n",
       "      <td>PE</td>\n",
       "      <td>S</td>\n",
       "      <td>480.323027</td>\n",
       "      <td>459.144006</td>\n",
       "      <td>465.806135</td>\n",
       "      <td>451.965435</td>\n",
       "      <td>453.224244</td>\n",
       "      <td>465.964228</td>\n",
       "      <td>453.113970</td>\n",
       "      <td>...</td>\n",
       "      <td>225.994536</td>\n",
       "      <td>235.223920</td>\n",
       "      <td>214.887030</td>\n",
       "      <td>149.215897</td>\n",
       "      <td>203.846432</td>\n",
       "      <td>260.299917</td>\n",
       "      <td>212.834458</td>\n",
       "      <td>186.280053</td>\n",
       "      <td>183.173238</td>\n",
       "      <td>178.159445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sta-1</td>\n",
       "      <td>PE</td>\n",
       "      <td>S</td>\n",
       "      <td>483.062214</td>\n",
       "      <td>461.269950</td>\n",
       "      <td>467.424315</td>\n",
       "      <td>445.979952</td>\n",
       "      <td>452.580405</td>\n",
       "      <td>467.572229</td>\n",
       "      <td>457.732677</td>\n",
       "      <td>...</td>\n",
       "      <td>239.204674</td>\n",
       "      <td>259.477788</td>\n",
       "      <td>227.491963</td>\n",
       "      <td>141.592199</td>\n",
       "      <td>197.435470</td>\n",
       "      <td>234.460851</td>\n",
       "      <td>214.729268</td>\n",
       "      <td>183.131163</td>\n",
       "      <td>182.824052</td>\n",
       "      <td>172.577740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sta-1</td>\n",
       "      <td>PE</td>\n",
       "      <td>S</td>\n",
       "      <td>479.616490</td>\n",
       "      <td>452.753328</td>\n",
       "      <td>463.973488</td>\n",
       "      <td>445.134221</td>\n",
       "      <td>454.169630</td>\n",
       "      <td>464.554485</td>\n",
       "      <td>453.358037</td>\n",
       "      <td>...</td>\n",
       "      <td>222.022200</td>\n",
       "      <td>251.411962</td>\n",
       "      <td>198.664733</td>\n",
       "      <td>140.124034</td>\n",
       "      <td>184.128513</td>\n",
       "      <td>240.662016</td>\n",
       "      <td>213.258294</td>\n",
       "      <td>166.104581</td>\n",
       "      <td>180.217319</td>\n",
       "      <td>179.859368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sta-1</td>\n",
       "      <td>PE</td>\n",
       "      <td>S</td>\n",
       "      <td>484.960405</td>\n",
       "      <td>454.415992</td>\n",
       "      <td>466.467296</td>\n",
       "      <td>451.892093</td>\n",
       "      <td>450.856426</td>\n",
       "      <td>464.397285</td>\n",
       "      <td>448.228246</td>\n",
       "      <td>...</td>\n",
       "      <td>222.294925</td>\n",
       "      <td>242.256284</td>\n",
       "      <td>213.171111</td>\n",
       "      <td>163.677922</td>\n",
       "      <td>174.868595</td>\n",
       "      <td>235.681321</td>\n",
       "      <td>211.009133</td>\n",
       "      <td>172.893660</td>\n",
       "      <td>193.773452</td>\n",
       "      <td>152.792827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename Plastic class  200.0904693  202.9747514  205.8580216  208.7402807  \\\n",
       "0    sta-1      PE     S   481.320059   456.004779   466.690553   448.377381   \n",
       "1    sta-1      PE     S   480.323027   459.144006   465.806135   451.965435   \n",
       "2    sta-1      PE     S   483.062214   461.269950   467.424315   445.979952   \n",
       "3    sta-1      PE     S   479.616490   452.753328   463.973488   445.134221   \n",
       "4    sta-1      PE     S   484.960405   454.415992   466.467296   451.892093   \n",
       "\n",
       "   211.6215296  214.501769  217.3809999  ...  3478.533384  3480.437351  \\\n",
       "0   455.065262  463.754197   452.444185  ...   222.087126   242.249061   \n",
       "1   453.224244  465.964228   453.113970  ...   225.994536   235.223920   \n",
       "2   452.580405  467.572229   457.732677  ...   239.204674   259.477788   \n",
       "3   454.169630  464.554485   453.358037  ...   222.022200   251.411962   \n",
       "4   450.856426  464.397285   448.228246  ...   222.294925   242.256284   \n",
       "\n",
       "   3482.340824  3484.243803  3486.146288  3488.048279  3489.949777  \\\n",
       "0   210.412050   151.576093   188.741190   244.907340   225.074543   \n",
       "1   214.887030   149.215897   203.846432   260.299917   212.834458   \n",
       "2   227.491963   141.592199   197.435470   234.460851   214.729268   \n",
       "3   198.664733   140.124034   184.128513   240.662016   213.258294   \n",
       "4   213.171111   163.677922   174.868595   235.681321   211.009133   \n",
       "\n",
       "   3491.850782  3493.751294  3495.651313  \n",
       "0   171.242801   188.412112   166.582477  \n",
       "1   186.280053   183.173238   178.159445  \n",
       "2   183.131163   182.824052   172.577740  \n",
       "3   166.104581   180.217319   179.859368  \n",
       "4   172.893660   193.773452   152.792827  \n",
       "\n",
       "[5 rows x 1415 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_input_data)\n",
    "Y= np.array(all_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 1, 1412)\n",
      "(1440, 1, 1412)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 12:12:33.379944: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-18 12:12:33.499464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742280153.542144   13059 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742280153.554289   13059 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-18 12:12:33.678785: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1742280155.431130   13059 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2618 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/ahaanbanerjee/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1412</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,893,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1412</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,893,188</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1412\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │     \u001b[38;5;34m2,893,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_9 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1412\u001b[0m)        │     \u001b[38;5;34m2,893,188\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,411,652</span> (43.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,411,652\u001b[0m (43.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,395,780</span> (43.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,395,780\u001b[0m (43.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,872</span> (62.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m15,872\u001b[0m (62.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, LeakyReLU\n",
    "from keras.models import Model\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (1,1412)\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=input_shape)\n",
    "encoded = Dense(2048)(input_layer)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "encoded = Dense(1024)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "encoded = Dense(512)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "encoded = Dense(256)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "encoded = Dense(128)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "# Latent Space (Feature Representation)\n",
    "latent_space = Dense(64, activation='linear')(encoded)  # Increased latent space size\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(128)(latent_space)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "decoded = Dense(256)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "decoded = Dense(512)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "decoded = Dense(1024)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "decoded = Dense(2048)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "# Output layer (Sigmoid for normalized data)\n",
    "decoded = Dense(1412, activation='sigmoid')(decoded)  # Sigmoid ensures output is between 0-1\n",
    "\n",
    "# Define Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the Autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mae')  # Use MAE for better reconstruction\n",
    "\n",
    "# Print model summary\n",
    "autoencoder.summary()\n",
    "\n",
    "# Define Encoder model (for extracting latent features)\n",
    "encoder_model = Model(input_layer, latent_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1412</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,893,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1412\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │     \u001b[38;5;34m2,893,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,705,152</span> (21.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,705,152\u001b[0m (21.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,697,216</span> (21.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,697,216\u001b[0m (21.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> (31.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,936\u001b[0m (31.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,X,test_size=0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742280197.338919   13937 service.cc:148] XLA service 0x7fa0e40143a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742280197.339054   13937 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-03-18 12:13:17.423192: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742280197.751585   13937 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-18 12:13:18.391765: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742280199.643701   13937 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-03-18 12:13:20.373599: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 360 bytes spill stores, 360 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.3099 - val_loss: 0.6717\n",
      "Epoch 2/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1386 - val_loss: 0.7132\n",
      "Epoch 3/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1065 - val_loss: 0.6261\n",
      "Epoch 4/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0884 - val_loss: 0.5460\n",
      "Epoch 5/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0893 - val_loss: 0.5329\n",
      "Epoch 6/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0755 - val_loss: 0.5055\n",
      "Epoch 7/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0744 - val_loss: 0.4812\n",
      "Epoch 8/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0686 - val_loss: 0.4292\n",
      "Epoch 9/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0669 - val_loss: 0.3837\n",
      "Epoch 10/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0659 - val_loss: 0.3499\n",
      "Epoch 11/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0640 - val_loss: 0.3761\n",
      "Epoch 12/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0684 - val_loss: 0.2884\n",
      "Epoch 13/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0618 - val_loss: 0.2339\n",
      "Epoch 14/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0618 - val_loss: 0.1431\n",
      "Epoch 15/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0624 - val_loss: 0.2750\n",
      "Epoch 16/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0523 - val_loss: 0.1853\n",
      "Epoch 17/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0589 - val_loss: 0.3072\n",
      "Epoch 18/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0588 - val_loss: 0.3000\n",
      "Epoch 19/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0613 - val_loss: 0.3532\n",
      "Epoch 20/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0581 - val_loss: 0.2444\n",
      "Epoch 21/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0608 - val_loss: 0.1860\n",
      "Epoch 22/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0542 - val_loss: 0.2605\n",
      "Epoch 23/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0550 - val_loss: 0.1876\n",
      "Epoch 24/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0671 - val_loss: 0.2613\n",
      "Epoch 25/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0571 - val_loss: 0.2167\n",
      "Epoch 26/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0539 - val_loss: 0.1215\n",
      "Epoch 27/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0436 - val_loss: 0.0743\n",
      "Epoch 28/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0389 - val_loss: 0.0657\n",
      "Epoch 29/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0431 - val_loss: 0.0585\n",
      "Epoch 30/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0393 - val_loss: 0.0707\n",
      "Epoch 31/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0427 - val_loss: 0.0529\n",
      "Epoch 32/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0393 - val_loss: 0.0475\n",
      "Epoch 33/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0423 - val_loss: 0.0814\n",
      "Epoch 34/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0528 - val_loss: 0.1799\n",
      "Epoch 35/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0510 - val_loss: 0.1656\n",
      "Epoch 36/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0463 - val_loss: 0.1115\n",
      "Epoch 37/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0489 - val_loss: 0.1099\n",
      "Epoch 38/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0403 - val_loss: 0.0891\n",
      "Epoch 39/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0338 - val_loss: 0.0660\n",
      "Epoch 40/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0340 - val_loss: 0.0587\n",
      "Epoch 41/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0341 - val_loss: 0.0530\n",
      "Epoch 42/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0344 - val_loss: 0.0475\n",
      "Epoch 43/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0357 - val_loss: 0.0470\n",
      "Epoch 44/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0343 - val_loss: 0.0449\n",
      "Epoch 45/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0376 - val_loss: 0.0483\n",
      "Epoch 46/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0367 - val_loss: 0.0470\n",
      "Epoch 47/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0360 - val_loss: 0.0439\n",
      "Epoch 48/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0330 - val_loss: 0.0454\n",
      "Epoch 49/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0367 - val_loss: 0.0376\n",
      "Epoch 50/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0373 - val_loss: 0.0352\n",
      "Epoch 51/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0317 - val_loss: 0.0368\n",
      "Epoch 52/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0361 - val_loss: 0.0357\n",
      "Epoch 53/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0301 - val_loss: 0.0344\n",
      "Epoch 54/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0298 - val_loss: 0.0307\n",
      "Epoch 55/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0315 - val_loss: 0.0405\n",
      "Epoch 56/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0356 - val_loss: 0.0459\n",
      "Epoch 57/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0330 - val_loss: 0.0469\n",
      "Epoch 58/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0329 - val_loss: 0.0423\n",
      "Epoch 59/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0316 - val_loss: 0.0395\n",
      "Epoch 60/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0300 - val_loss: 0.0352\n",
      "Epoch 61/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0296 - val_loss: 0.0324\n",
      "Epoch 62/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0291 - val_loss: 0.0308\n",
      "Epoch 63/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0287 - val_loss: 0.0290\n",
      "Epoch 64/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0276 - val_loss: 0.0270\n",
      "Epoch 65/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0281 - val_loss: 0.0287\n",
      "Epoch 66/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0284 - val_loss: 0.0272\n",
      "Epoch 67/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0303 - val_loss: 0.0290\n",
      "Epoch 68/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0284 - val_loss: 0.0286\n",
      "Epoch 69/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0275 - val_loss: 0.0253\n",
      "Epoch 70/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0277 - val_loss: 0.0253\n",
      "Epoch 71/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0278 - val_loss: 0.0275\n",
      "Epoch 72/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0273 - val_loss: 0.0247\n",
      "Epoch 73/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0301 - val_loss: 0.0296\n",
      "Epoch 74/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0270 - val_loss: 0.0259\n",
      "Epoch 75/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0280 - val_loss: 0.0264\n",
      "Epoch 76/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0282 - val_loss: 0.0306\n",
      "Epoch 77/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0312 - val_loss: 0.0272\n",
      "Epoch 78/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0271 - val_loss: 0.0317\n",
      "Epoch 79/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0306 - val_loss: 0.0287\n",
      "Epoch 80/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0268 - val_loss: 0.0269\n",
      "Epoch 81/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0270 - val_loss: 0.0259\n",
      "Epoch 82/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0303 - val_loss: 0.0332\n",
      "Epoch 83/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0311 - val_loss: 0.0317\n",
      "Epoch 84/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0280 - val_loss: 0.0290\n",
      "Epoch 85/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0320 - val_loss: 0.0387\n",
      "Epoch 86/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0297 - val_loss: 0.0440\n",
      "Epoch 87/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0272 - val_loss: 0.0438\n",
      "Epoch 88/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0246 - val_loss: 0.0367\n",
      "Epoch 89/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0285 - val_loss: 0.0602\n",
      "Epoch 90/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0331 - val_loss: 0.0749\n",
      "Epoch 91/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0316 - val_loss: 0.0762\n",
      "Epoch 92/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0325 - val_loss: 0.0699\n",
      "Epoch 93/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0317 - val_loss: 0.0665\n",
      "Epoch 94/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0297 - val_loss: 0.0661\n",
      "Epoch 95/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0319 - val_loss: 0.0766\n",
      "Epoch 96/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0316 - val_loss: 0.0789\n",
      "Epoch 97/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0302 - val_loss: 0.0678\n",
      "Epoch 98/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0306 - val_loss: 0.0607\n",
      "Epoch 99/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0270 - val_loss: 0.0656\n",
      "Epoch 100/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0284 - val_loss: 0.0600\n",
      "Epoch 101/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0251 - val_loss: 0.0579\n",
      "Epoch 102/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0290 - val_loss: 0.0547\n",
      "Epoch 103/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0279 - val_loss: 0.0461\n",
      "Epoch 104/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0419\n",
      "Epoch 105/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0262 - val_loss: 0.0351\n",
      "Epoch 106/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0275 - val_loss: 0.0457\n",
      "Epoch 107/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0278 - val_loss: 0.0362\n",
      "Epoch 108/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0303 - val_loss: 0.0467\n",
      "Epoch 109/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0302 - val_loss: 0.0436\n",
      "Epoch 110/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0280 - val_loss: 0.0434\n",
      "Epoch 111/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0313 - val_loss: 0.0371\n",
      "Epoch 112/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0319 - val_loss: 0.0446\n",
      "Epoch 113/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0328 - val_loss: 0.0792\n",
      "Epoch 114/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0342 - val_loss: 0.0645\n",
      "Epoch 115/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0317 - val_loss: 0.0481\n",
      "Epoch 116/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0285 - val_loss: 0.0393\n",
      "Epoch 117/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0256 - val_loss: 0.0362\n",
      "Epoch 118/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0266 - val_loss: 0.0275\n",
      "Epoch 119/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0259 - val_loss: 0.0290\n",
      "Epoch 120/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0258 - val_loss: 0.0292\n",
      "Epoch 121/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0255 - val_loss: 0.0230\n",
      "Epoch 122/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0245 - val_loss: 0.0262\n",
      "Epoch 123/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0247 - val_loss: 0.0265\n",
      "Epoch 124/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0262 - val_loss: 0.0229\n",
      "Epoch 125/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0222 - val_loss: 0.0270\n",
      "Epoch 126/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0254 - val_loss: 0.0222\n",
      "Epoch 127/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0236 - val_loss: 0.0244\n",
      "Epoch 128/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0253 - val_loss: 0.0257\n",
      "Epoch 129/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0281 - val_loss: 0.0246\n",
      "Epoch 130/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0273 - val_loss: 0.0247\n",
      "Epoch 131/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0261 - val_loss: 0.0381\n",
      "Epoch 132/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0256 - val_loss: 0.0390\n",
      "Epoch 133/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0327 - val_loss: 0.1471\n",
      "Epoch 134/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0309 - val_loss: 0.1330\n",
      "Epoch 135/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0302 - val_loss: 0.1185\n",
      "Epoch 136/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0266 - val_loss: 0.0891\n",
      "Epoch 137/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0278 - val_loss: 0.0435\n",
      "Epoch 138/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0281 - val_loss: 0.0475\n",
      "Epoch 139/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0264 - val_loss: 0.0400\n",
      "Epoch 140/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0255 - val_loss: 0.0323\n",
      "Epoch 141/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0252 - val_loss: 0.0314\n",
      "Epoch 142/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0290 - val_loss: 0.0392\n",
      "Epoch 143/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0248 - val_loss: 0.0292\n",
      "Epoch 144/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0247 - val_loss: 0.0287\n",
      "Epoch 145/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0245 - val_loss: 0.0309\n",
      "Epoch 146/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0250 - val_loss: 0.0237\n",
      "Epoch 147/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0245 - val_loss: 0.0221\n",
      "Epoch 148/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0252 - val_loss: 0.0230\n",
      "Epoch 149/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0222 - val_loss: 0.0215\n",
      "Epoch 150/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0243 - val_loss: 0.0218\n",
      "Epoch 151/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0224 - val_loss: 0.0243\n",
      "Epoch 152/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 153/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0279 - val_loss: 0.0368\n",
      "Epoch 154/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0294 - val_loss: 0.0386\n",
      "Epoch 155/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0306 - val_loss: 0.0404\n",
      "Epoch 156/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0295 - val_loss: 0.0401\n",
      "Epoch 157/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0264 - val_loss: 0.0345\n",
      "Epoch 158/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0258 - val_loss: 0.0337\n",
      "Epoch 159/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0267 - val_loss: 0.0292\n",
      "Epoch 160/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0268 - val_loss: 0.0286\n",
      "Epoch 161/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0252 - val_loss: 0.0269\n",
      "Epoch 162/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0241 - val_loss: 0.0276\n",
      "Epoch 163/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0250 - val_loss: 0.0217\n",
      "Epoch 164/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0268 - val_loss: 0.0241\n",
      "Epoch 165/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0276 - val_loss: 0.0363\n",
      "Epoch 166/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0268 - val_loss: 0.0303\n",
      "Epoch 167/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0274 - val_loss: 0.0507\n",
      "Epoch 168/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0266 - val_loss: 0.0516\n",
      "Epoch 169/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0234 - val_loss: 0.0474\n",
      "Epoch 170/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0232 - val_loss: 0.0413\n",
      "Epoch 171/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0243 - val_loss: 0.0372\n",
      "Epoch 172/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0251 - val_loss: 0.0369\n",
      "Epoch 173/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0277 - val_loss: 0.0386\n",
      "Epoch 174/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0300 - val_loss: 0.0418\n",
      "Epoch 175/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0265 - val_loss: 0.0430\n",
      "Epoch 176/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0266 - val_loss: 0.0374\n",
      "Epoch 177/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0255 - val_loss: 0.0355\n",
      "Epoch 178/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0232 - val_loss: 0.0311\n",
      "Epoch 179/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0216 - val_loss: 0.0299\n",
      "Epoch 180/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0226 - val_loss: 0.0275\n",
      "Epoch 181/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0243 - val_loss: 0.0513\n",
      "Epoch 182/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0249 - val_loss: 0.0407\n",
      "Epoch 183/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0245 - val_loss: 0.0378\n",
      "Epoch 184/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0275 - val_loss: 0.0394\n",
      "Epoch 185/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0291 - val_loss: 0.0439\n",
      "Epoch 186/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0285 - val_loss: 0.0401\n",
      "Epoch 187/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0280 - val_loss: 0.0376\n",
      "Epoch 188/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0246 - val_loss: 0.0328\n",
      "Epoch 189/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0244 - val_loss: 0.0296\n",
      "Epoch 190/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0255 - val_loss: 0.0304\n",
      "Epoch 191/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0227 - val_loss: 0.0264\n",
      "Epoch 192/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0227 - val_loss: 0.0246\n",
      "Epoch 193/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0264 - val_loss: 0.0268\n",
      "Epoch 194/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0242 - val_loss: 0.0259\n",
      "Epoch 195/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0295 - val_loss: 0.0291\n",
      "Epoch 196/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0299 - val_loss: 0.0682\n",
      "Epoch 197/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0284 - val_loss: 0.0857\n",
      "Epoch 198/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0314 - val_loss: 0.1097\n",
      "Epoch 199/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0288 - val_loss: 0.0856\n",
      "Epoch 200/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0264 - val_loss: 0.0707\n",
      "Epoch 201/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0251 - val_loss: 0.0596\n",
      "Epoch 202/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0239 - val_loss: 0.0470\n",
      "Epoch 203/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0223 - val_loss: 0.0422\n",
      "Epoch 204/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0249 - val_loss: 0.0382\n",
      "Epoch 205/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0248 - val_loss: 0.0414\n",
      "Epoch 206/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0246 - val_loss: 0.0369\n",
      "Epoch 207/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0259 - val_loss: 0.0396\n",
      "Epoch 208/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0289 - val_loss: 0.1458\n",
      "Epoch 209/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0405 - val_loss: 0.1860\n",
      "Epoch 210/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0344 - val_loss: 0.1423\n",
      "Epoch 211/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0337 - val_loss: 0.1182\n",
      "Epoch 212/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0312 - val_loss: 0.0933\n",
      "Epoch 213/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0276 - val_loss: 0.0917\n",
      "Epoch 214/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0258 - val_loss: 0.0738\n",
      "Epoch 215/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0266 - val_loss: 0.0655\n",
      "Epoch 216/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0244 - val_loss: 0.0555\n",
      "Epoch 217/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0265 - val_loss: 0.0533\n",
      "Epoch 218/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0291 - val_loss: 0.0468\n",
      "Epoch 219/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0285 - val_loss: 0.0462\n",
      "Epoch 220/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0255 - val_loss: 0.0401\n",
      "Epoch 221/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0243 - val_loss: 0.0340\n",
      "Epoch 222/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0236 - val_loss: 0.0311\n",
      "Epoch 223/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0232 - val_loss: 0.0308\n",
      "Epoch 224/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0245 - val_loss: 0.0291\n",
      "Epoch 225/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0217 - val_loss: 0.0274\n",
      "Epoch 226/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0265 - val_loss: 0.0238\n",
      "Epoch 227/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0241 - val_loss: 0.0254\n",
      "Epoch 228/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0239 - val_loss: 0.0284\n",
      "Epoch 229/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0267 - val_loss: 0.0293\n",
      "Epoch 230/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0261 - val_loss: 0.0356\n",
      "Epoch 231/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0261 - val_loss: 0.0271\n",
      "Epoch 232/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0256 - val_loss: 0.0249\n",
      "Epoch 233/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0259 - val_loss: 0.0249\n",
      "Epoch 234/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0253 - val_loss: 0.0239\n",
      "Epoch 235/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0240 - val_loss: 0.0207\n",
      "Epoch 236/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0234 - val_loss: 0.0207\n",
      "Epoch 237/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0248 - val_loss: 0.0239\n",
      "Epoch 238/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0256 - val_loss: 0.0224\n",
      "Epoch 239/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0246 - val_loss: 0.0256\n",
      "Epoch 240/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0278\n",
      "Epoch 241/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0267\n",
      "Epoch 242/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0235 - val_loss: 0.0240\n",
      "Epoch 243/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0231 - val_loss: 0.0228\n",
      "Epoch 244/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 245/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0234 - val_loss: 0.0231\n",
      "Epoch 246/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0230 - val_loss: 0.0248\n",
      "Epoch 247/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0241 - val_loss: 0.0229\n",
      "Epoch 248/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0235 - val_loss: 0.0226\n",
      "Epoch 249/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0223 - val_loss: 0.0248\n",
      "Epoch 250/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0241 - val_loss: 0.0271\n",
      "Epoch 251/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0234 - val_loss: 0.0259\n",
      "Epoch 252/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0230 - val_loss: 0.0235\n",
      "Epoch 253/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0235 - val_loss: 0.0231\n",
      "Epoch 254/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0250 - val_loss: 0.0227\n",
      "Epoch 255/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0224 - val_loss: 0.0241\n",
      "Epoch 256/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0229 - val_loss: 0.0244\n",
      "Epoch 257/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0208 - val_loss: 0.0240\n",
      "Epoch 258/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0239 - val_loss: 0.0203\n",
      "Epoch 259/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0247 - val_loss: 0.0235\n",
      "Epoch 260/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0245 - val_loss: 0.0205\n",
      "Epoch 261/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0229 - val_loss: 0.0234\n",
      "Epoch 262/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0244 - val_loss: 0.0211\n",
      "Epoch 263/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 264/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0221 - val_loss: 0.0189\n",
      "Epoch 265/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0214 - val_loss: 0.0222\n",
      "Epoch 266/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0220 - val_loss: 0.0205\n",
      "Epoch 267/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0250 - val_loss: 0.0214\n",
      "Epoch 268/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 269/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0199\n",
      "Epoch 270/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0222 - val_loss: 0.0236\n",
      "Epoch 271/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0228 - val_loss: 0.0205\n",
      "Epoch 272/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0235 - val_loss: 0.0245\n",
      "Epoch 273/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0235 - val_loss: 0.0292\n",
      "Epoch 274/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0232 - val_loss: 0.0263\n",
      "Epoch 275/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0219 - val_loss: 0.0228\n",
      "Epoch 276/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0218 - val_loss: 0.0188\n",
      "Epoch 277/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0218 - val_loss: 0.0202\n",
      "Epoch 278/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0211 - val_loss: 0.0257\n",
      "Epoch 279/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0226 - val_loss: 0.0229\n",
      "Epoch 280/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0224 - val_loss: 0.0245\n",
      "Epoch 281/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0211 - val_loss: 0.0223\n",
      "Epoch 282/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0245 - val_loss: 0.0248\n",
      "Epoch 283/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0257 - val_loss: 0.0714\n",
      "Epoch 284/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0293 - val_loss: 0.0804\n",
      "Epoch 285/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0268 - val_loss: 0.0747\n",
      "Epoch 286/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0258 - val_loss: 0.0627\n",
      "Epoch 287/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0248 - val_loss: 0.0481\n",
      "Epoch 288/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0255 - val_loss: 0.0468\n",
      "Epoch 289/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0249 - val_loss: 0.0451\n",
      "Epoch 290/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0240 - val_loss: 0.0581\n",
      "Epoch 291/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0234 - val_loss: 0.0505\n",
      "Epoch 292/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0218 - val_loss: 0.0476\n",
      "Epoch 293/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0252 - val_loss: 0.0480\n",
      "Epoch 294/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0205 - val_loss: 0.0388\n",
      "Epoch 295/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0231 - val_loss: 0.0466\n",
      "Epoch 296/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0236 - val_loss: 0.0490\n",
      "Epoch 297/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0218 - val_loss: 0.0443\n",
      "Epoch 298/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0217 - val_loss: 0.0433\n",
      "Epoch 299/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0228 - val_loss: 0.0418\n",
      "Epoch 300/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0227 - val_loss: 0.0367\n",
      "Epoch 301/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0229 - val_loss: 0.0339\n",
      "Epoch 302/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0213 - val_loss: 0.0278\n",
      "Epoch 303/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0223 - val_loss: 0.0284\n",
      "Epoch 304/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0264 - val_loss: 0.0359\n",
      "Epoch 305/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0248 - val_loss: 0.0380\n",
      "Epoch 306/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0217 - val_loss: 0.0353\n",
      "Epoch 307/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0240 - val_loss: 0.0312\n",
      "Epoch 308/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0243 - val_loss: 0.0282\n",
      "Epoch 309/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0214 - val_loss: 0.0290\n",
      "Epoch 310/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0209 - val_loss: 0.0262\n",
      "Epoch 311/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0203 - val_loss: 0.0262\n",
      "Epoch 312/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0210 - val_loss: 0.0230\n",
      "Epoch 313/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0195 - val_loss: 0.0240\n",
      "Epoch 314/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0206 - val_loss: 0.0226\n",
      "Epoch 315/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0208 - val_loss: 0.0237\n",
      "Epoch 316/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0195 - val_loss: 0.0459\n",
      "Epoch 317/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0267 - val_loss: 0.0608\n",
      "Epoch 318/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0250 - val_loss: 0.0569\n",
      "Epoch 319/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0225 - val_loss: 0.0361\n",
      "Epoch 320/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0293\n",
      "Epoch 321/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0213 - val_loss: 0.0246\n",
      "Epoch 322/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0200 - val_loss: 0.0238\n",
      "Epoch 323/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0212 - val_loss: 0.0232\n",
      "Epoch 324/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 325/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 326/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 327/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0203 - val_loss: 0.0195\n",
      "Epoch 328/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 329/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0219 - val_loss: 0.0190\n",
      "Epoch 330/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0197 - val_loss: 0.0191\n",
      "Epoch 331/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0187 - val_loss: 0.0181\n",
      "Epoch 332/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0199 - val_loss: 0.0195\n",
      "Epoch 333/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0195 - val_loss: 0.0239\n",
      "Epoch 334/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0180 - val_loss: 0.0229\n",
      "Epoch 335/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0232 - val_loss: 0.0219\n",
      "Epoch 336/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 337/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0192 - val_loss: 0.0190\n",
      "Epoch 338/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0201 - val_loss: 0.0198\n",
      "Epoch 339/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 340/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0214 - val_loss: 0.0224\n",
      "Epoch 341/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0221 - val_loss: 0.0264\n",
      "Epoch 342/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0195 - val_loss: 0.0218\n",
      "Epoch 343/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 344/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 345/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0209 - val_loss: 0.0197\n",
      "Epoch 346/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0178 - val_loss: 0.0183\n",
      "Epoch 347/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0208 - val_loss: 0.0165\n",
      "Epoch 348/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0206 - val_loss: 0.0168\n",
      "Epoch 349/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0197 - val_loss: 0.0205\n",
      "Epoch 350/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0190 - val_loss: 0.0171\n",
      "Epoch 351/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0181 - val_loss: 0.0148\n",
      "Epoch 352/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0173 - val_loss: 0.0152\n",
      "Epoch 353/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0182 - val_loss: 0.0199\n",
      "Epoch 354/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0193 - val_loss: 0.0194\n",
      "Epoch 355/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 356/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0190 - val_loss: 0.0163\n",
      "Epoch 357/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0181 - val_loss: 0.0160\n",
      "Epoch 358/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0203 - val_loss: 0.0159\n",
      "Epoch 359/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0187 - val_loss: 0.0222\n",
      "Epoch 360/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 361/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0219 - val_loss: 0.0196\n",
      "Epoch 362/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0216 - val_loss: 0.0177\n",
      "Epoch 363/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0196 - val_loss: 0.0167\n",
      "Epoch 364/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0208 - val_loss: 0.0185\n",
      "Epoch 365/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0206 - val_loss: 0.0152\n",
      "Epoch 366/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0184 - val_loss: 0.0158\n",
      "Epoch 367/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0186 - val_loss: 0.0170\n",
      "Epoch 368/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0195 - val_loss: 0.0174\n",
      "Epoch 369/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0198 - val_loss: 0.0158\n",
      "Epoch 370/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 371/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0188 - val_loss: 0.0276\n",
      "Epoch 372/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0195 - val_loss: 0.0258\n",
      "Epoch 373/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0205 - val_loss: 0.0264\n",
      "Epoch 374/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0199 - val_loss: 0.0252\n",
      "Epoch 375/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0178 - val_loss: 0.0245\n",
      "Epoch 376/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0179 - val_loss: 0.0230\n",
      "Epoch 377/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0204 - val_loss: 0.0188\n",
      "Epoch 378/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 379/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0205 - val_loss: 0.0175\n",
      "Epoch 380/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169 - val_loss: 0.0177\n",
      "Epoch 381/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0182 - val_loss: 0.0162\n",
      "Epoch 382/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0173 - val_loss: 0.0170\n",
      "Epoch 383/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0197 - val_loss: 0.0161\n",
      "Epoch 384/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0205 - val_loss: 0.0150\n",
      "Epoch 385/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0175 - val_loss: 0.0148\n",
      "Epoch 386/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0181 - val_loss: 0.0168\n",
      "Epoch 387/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0184 - val_loss: 0.0165\n",
      "Epoch 388/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 389/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0181 - val_loss: 0.0170\n",
      "Epoch 390/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0177 - val_loss: 0.0160\n",
      "Epoch 391/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0173 - val_loss: 0.0163\n",
      "Epoch 392/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0190 - val_loss: 0.0173\n",
      "Epoch 393/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0171 - val_loss: 0.0233\n",
      "Epoch 394/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0189 - val_loss: 0.0269\n",
      "Epoch 395/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0180 - val_loss: 0.0278\n",
      "Epoch 396/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0187 - val_loss: 0.0246\n",
      "Epoch 397/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0182 - val_loss: 0.0229\n",
      "Epoch 398/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0178 - val_loss: 0.0201\n",
      "Epoch 399/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 400/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0176 - val_loss: 0.0168\n",
      "Epoch 401/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0192 - val_loss: 0.0171\n",
      "Epoch 402/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0188 - val_loss: 0.0161\n",
      "Epoch 403/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 404/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0162 - val_loss: 0.0159\n",
      "Epoch 405/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0199 - val_loss: 0.0159\n",
      "Epoch 406/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0180 - val_loss: 0.0160\n",
      "Epoch 407/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0182 - val_loss: 0.0158\n",
      "Epoch 408/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0168 - val_loss: 0.0154\n",
      "Epoch 409/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 410/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0200 - val_loss: 0.0153\n",
      "Epoch 411/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 412/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0179 - val_loss: 0.0146\n",
      "Epoch 413/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - val_loss: 0.0155\n",
      "Epoch 414/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0167 - val_loss: 0.0142\n",
      "Epoch 415/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169 - val_loss: 0.0142\n",
      "Epoch 416/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 417/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 418/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0163 - val_loss: 0.0141\n",
      "Epoch 419/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169 - val_loss: 0.0150\n",
      "Epoch 420/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0177 - val_loss: 0.0158\n",
      "Epoch 421/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0194 - val_loss: 0.0147\n",
      "Epoch 422/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0184 - val_loss: 0.0166\n",
      "Epoch 423/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0165 - val_loss: 0.0152\n",
      "Epoch 424/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0174 - val_loss: 0.0137\n",
      "Epoch 425/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 426/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0198 - val_loss: 0.0173\n",
      "Epoch 427/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 428/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0193 - val_loss: 0.0162\n",
      "Epoch 429/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 430/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0190 - val_loss: 0.0152\n",
      "Epoch 431/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 432/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0190 - val_loss: 0.0150\n",
      "Epoch 433/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 434/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0162 - val_loss: 0.0153\n",
      "Epoch 435/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0180 - val_loss: 0.0158\n",
      "Epoch 436/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0165 - val_loss: 0.0156\n",
      "Epoch 437/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0166 - val_loss: 0.0151\n",
      "Epoch 438/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0185 - val_loss: 0.0157\n",
      "Epoch 439/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0165 - val_loss: 0.0147\n",
      "Epoch 440/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 441/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0167 - val_loss: 0.0152\n",
      "Epoch 442/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0183 - val_loss: 0.0146\n",
      "Epoch 443/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0178 - val_loss: 0.0157\n",
      "Epoch 444/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0700\n",
      "Epoch 445/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0316 - val_loss: 0.1410\n",
      "Epoch 446/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0316 - val_loss: 0.1471\n",
      "Epoch 447/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0278 - val_loss: 0.1596\n",
      "Epoch 448/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0251 - val_loss: 0.1122\n",
      "Epoch 449/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0249 - val_loss: 0.0746\n",
      "Epoch 450/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0229 - val_loss: 0.0640\n",
      "Epoch 451/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0202 - val_loss: 0.0468\n",
      "Epoch 452/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0201 - val_loss: 0.0420\n",
      "Epoch 453/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0196 - val_loss: 0.0341\n",
      "Epoch 454/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0220 - val_loss: 0.0337\n",
      "Epoch 455/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0199 - val_loss: 0.0311\n",
      "Epoch 456/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0205 - val_loss: 0.0278\n",
      "Epoch 457/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0202 - val_loss: 0.0373\n",
      "Epoch 458/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0187 - val_loss: 0.0297\n",
      "Epoch 459/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0254 - val_loss: 0.0304\n",
      "Epoch 460/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0213 - val_loss: 0.0259\n",
      "Epoch 461/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0196 - val_loss: 0.0256\n",
      "Epoch 462/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0186 - val_loss: 0.0244\n",
      "Epoch 463/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 464/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0176 - val_loss: 0.0192\n",
      "Epoch 465/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0186 - val_loss: 0.0183\n",
      "Epoch 466/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0157 - val_loss: 0.0179\n",
      "Epoch 467/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0171 - val_loss: 0.0161\n",
      "Epoch 468/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0181 - val_loss: 0.0173\n",
      "Epoch 469/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 470/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0188 - val_loss: 0.0170\n",
      "Epoch 471/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0171 - val_loss: 0.0160\n",
      "Epoch 472/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0194 - val_loss: 0.0171\n",
      "Epoch 473/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0175 - val_loss: 0.0164\n",
      "Epoch 474/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - val_loss: 0.0184\n",
      "Epoch 475/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 476/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0180 - val_loss: 0.0158\n",
      "Epoch 477/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0178 - val_loss: 0.0150\n",
      "Epoch 478/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 479/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0167 - val_loss: 0.0156\n",
      "Epoch 480/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0188 - val_loss: 0.0162\n",
      "Epoch 481/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - val_loss: 0.0190\n",
      "Epoch 482/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0178 - val_loss: 0.0209\n",
      "Epoch 483/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - val_loss: 0.0190\n",
      "Epoch 484/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 485/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 486/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0174 - val_loss: 0.0155\n",
      "Epoch 487/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 488/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0158 - val_loss: 0.0152\n",
      "Epoch 489/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0175 - val_loss: 0.0156\n",
      "Epoch 490/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0186 - val_loss: 0.0156\n",
      "Epoch 491/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - val_loss: 0.0149\n",
      "Epoch 492/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0190 - val_loss: 0.0159\n",
      "Epoch 493/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0174 - val_loss: 0.0148\n",
      "Epoch 494/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169 - val_loss: 0.0150\n",
      "Epoch 495/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0173 - val_loss: 0.0162\n",
      "Epoch 496/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0190 - val_loss: 0.0148\n",
      "Epoch 497/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0165 - val_loss: 0.0157\n",
      "Epoch 498/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0165 - val_loss: 0.0146\n",
      "Epoch 499/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0161 - val_loss: 0.0142\n",
      "Epoch 500/500\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0186 - val_loss: 0.0145\n"
     ]
    }
   ],
   "source": [
    "history=autoencoder.fit(X_train,X_train,validation_data=(X_test, X_test),batch_size=128,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "\n",
    "# Check if validation loss is available and plot it\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.saving.save_model(encoder_model,'/media/ahaanbanerjee/Crucial X9/Capstone/Models/_Encoder_binary.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "encoder_model.save('/media/ahaanbanerjee/Crucial X9/Capstone/Models/_Encoder_binary.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1412</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,893,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1412\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │     \u001b[38;5;34m2,893,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,705,152</span> (21.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,705,152\u001b[0m (21.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,697,216</span> (21.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,697,216\u001b[0m (21.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> (31.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,936\u001b[0m (31.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "encoder_model = load_model(\"/media/ahaanbanerjee/Crucial X9/Capstone/Models/_Encoder_binary.h5\")\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.get_layer(index=6).get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 11:26:52.577639: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-14 11:26:52.585757: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741931812.595242  134841 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741931812.597986  134841 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-14 11:26:52.607705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras import regularizers, backend as K\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_regularizer(activation_matrix):\n",
    "    p = 0.01  # Target sparsity level\n",
    "    beta = 3\n",
    "\n",
    "    p_hat = tf.reduce_mean(activation_matrix)  # Mean activation\n",
    "    p_hat = tf.clip_by_value(p_hat, 1e-8, 1 - 1e-8)  # Avoid log(0)\n",
    "\n",
    "    KL_divergence = p * tf.math.log(p / p_hat) + (1 - p) * tf.math.log((1 - p) / (1 - p_hat))\n",
    "    \n",
    "    return beta * tf.reduce_sum(KL_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741931889.952289  134841 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1159 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/ahaanbanerjee/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1412</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,893,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1412</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,893,188</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1412\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │     \u001b[38;5;34m2,893,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_9 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1412\u001b[0m)        │     \u001b[38;5;34m2,893,188\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,411,652</span> (43.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,411,652\u001b[0m (43.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,395,780</span> (43.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,395,780\u001b[0m (43.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,872</span> (62.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m15,872\u001b[0m (62.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, ActivityRegularization\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (1,1412)\n",
    "lambda_ = 0.001 \n",
    "# Encoder\n",
    "input_layer = Input(shape=input_shape)\n",
    "encoded = Dense(2048, kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(input_layer)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "encoded = Dense(1024, kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "encoded = Dense(512, kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "encoded = Dense(256, kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "\n",
    "encoded = Dense(128, kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "# Latent Space (Feature Representation)\n",
    "latent_space = Dense(64, activation='linear')(encoded)  # Increased latent space size\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(128,kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(latent_space)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "decoded = Dense(256,kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "decoded = Dense(512,kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "decoded = Dense(1024,kernel_regularizer=regularizers.l2(lambda_/2),activity_regularizer=sparse_regularizer)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "decoded = Dense(2048,kernel_regularizer=regularizers.l2(lambda_/2))(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "# Output layer (Sigmoid for normalized data)\n",
    "decoded = Dense(1412, activation='sigmoid')(decoded)  # Sigmoid ensures output is between 0-1\n",
    "\n",
    "# Define Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the Autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mae')  \n",
    "\n",
    "# Print model summary\n",
    "autoencoder.summary()\n",
    "\n",
    "# Define Encoder model (for extracting latent features)\n",
    "encoder_model = Model(input_layer, latent_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741931971.880718  134964 service.cc:148] XLA service 0x7efca40022f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741931971.880740  134964 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-03-14 11:29:32.030317: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741931972.425629  134964 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-14 11:29:33.038053: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.8524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741931974.893599  134964 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.8094  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 11:29:38.144204: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - loss: 5.7879 - val_loss: 5.9723\n",
      "Epoch 2/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.0518 - val_loss: 4.6214\n",
      "Epoch 3/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7924 - val_loss: 4.3577\n",
      "Epoch 4/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4884 - val_loss: 4.2149\n",
      "Epoch 5/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.3034 - val_loss: 4.2310\n",
      "Epoch 6/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1585 - val_loss: 4.4443\n",
      "Epoch 7/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0182 - val_loss: 4.5329\n",
      "Epoch 8/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8960 - val_loss: 4.1593\n",
      "Epoch 9/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7813 - val_loss: 4.0842\n",
      "Epoch 10/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6863 - val_loss: 4.2079\n",
      "Epoch 11/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5970 - val_loss: 3.7474\n",
      "Epoch 12/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5084 - val_loss: 3.4718\n",
      "Epoch 13/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4234 - val_loss: 3.4265\n",
      "Epoch 14/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.3459 - val_loss: 3.6291\n",
      "Epoch 15/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2794 - val_loss: 3.8748\n",
      "Epoch 16/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2084 - val_loss: 4.1775\n",
      "Epoch 17/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1343 - val_loss: 4.1131\n",
      "Epoch 18/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0792 - val_loss: 3.7741\n",
      "Epoch 19/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0256 - val_loss: 3.7163\n",
      "Epoch 20/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9701 - val_loss: 3.6712\n",
      "Epoch 21/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9292 - val_loss: 3.9679\n",
      "Epoch 22/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8727 - val_loss: 3.8876\n",
      "Epoch 23/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8358 - val_loss: 3.8352\n",
      "Epoch 24/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7869 - val_loss: 4.1475\n",
      "Epoch 25/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7328 - val_loss: 4.1134\n",
      "Epoch 26/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6990 - val_loss: 3.7237\n",
      "Epoch 27/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6620 - val_loss: 4.0579\n",
      "Epoch 28/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6455 - val_loss: 4.3705\n",
      "Epoch 29/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6147 - val_loss: 4.5528\n",
      "Epoch 30/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5890 - val_loss: 4.7036\n",
      "Epoch 31/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5513 - val_loss: 4.6632\n",
      "Epoch 32/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5261 - val_loss: 4.3124\n",
      "Epoch 33/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5007 - val_loss: 4.2418\n",
      "Epoch 34/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4691 - val_loss: 4.2219\n",
      "Epoch 35/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4613 - val_loss: 4.2064\n",
      "Epoch 36/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4448 - val_loss: 3.8460\n",
      "Epoch 37/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4195 - val_loss: 3.8011\n",
      "Epoch 38/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4008 - val_loss: 3.7765\n",
      "Epoch 39/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3800 - val_loss: 3.7559\n",
      "Epoch 40/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3623 - val_loss: 3.7384\n",
      "Epoch 41/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3439 - val_loss: 3.7108\n",
      "Epoch 42/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3337 - val_loss: 3.7106\n",
      "Epoch 43/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3017 - val_loss: 3.6768\n",
      "Epoch 44/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2890 - val_loss: 3.6804\n",
      "Epoch 45/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2784 - val_loss: 3.7023\n",
      "Epoch 46/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2576 - val_loss: 4.0285\n",
      "Epoch 47/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2533 - val_loss: 4.0150\n",
      "Epoch 48/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2290 - val_loss: 3.6239\n",
      "Epoch 49/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2087 - val_loss: 3.6029\n",
      "Epoch 50/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2086 - val_loss: 3.6616\n",
      "Epoch 51/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2083 - val_loss: 2.7785\n",
      "Epoch 52/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1933 - val_loss: 3.3614\n",
      "Epoch 53/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1700 - val_loss: 3.7968\n",
      "Epoch 54/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1585 - val_loss: 3.8075\n",
      "Epoch 55/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1377 - val_loss: 3.4536\n",
      "Epoch 56/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1170 - val_loss: 2.9787\n",
      "Epoch 57/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0966 - val_loss: 2.6570\n",
      "Epoch 58/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0802 - val_loss: 3.3042\n",
      "Epoch 59/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0704 - val_loss: 3.6223\n",
      "Epoch 60/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0513 - val_loss: 3.5743\n",
      "Epoch 61/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0372 - val_loss: 3.5213\n",
      "Epoch 62/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0220 - val_loss: 3.4729\n",
      "Epoch 63/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0110 - val_loss: 3.4396\n",
      "Epoch 64/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9958 - val_loss: 3.4127\n",
      "Epoch 65/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9915 - val_loss: 3.3900\n",
      "Epoch 66/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9729 - val_loss: 3.7501\n",
      "Epoch 67/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9630 - val_loss: 3.7324\n",
      "Epoch 68/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9454 - val_loss: 3.7209\n",
      "Epoch 69/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9431 - val_loss: 3.7134\n",
      "Epoch 70/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9301 - val_loss: 3.6946\n",
      "Epoch 71/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9163 - val_loss: 3.6770\n",
      "Epoch 72/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9102 - val_loss: 3.6683\n",
      "Epoch 73/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8981 - val_loss: 3.6598\n",
      "Epoch 74/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8892 - val_loss: 3.6544\n",
      "Epoch 75/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8832 - val_loss: 3.6468\n",
      "Epoch 76/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8760 - val_loss: 3.6436\n",
      "Epoch 77/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8685 - val_loss: 3.6477\n",
      "Epoch 78/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8647 - val_loss: 3.7075\n",
      "Epoch 79/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8523 - val_loss: 4.0008\n",
      "Epoch 80/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8464 - val_loss: 3.9975\n",
      "Epoch 81/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8402 - val_loss: 3.9941\n",
      "Epoch 82/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8305 - val_loss: 3.6676\n",
      "Epoch 83/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8261 - val_loss: 3.5919\n",
      "Epoch 84/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8195 - val_loss: 3.5981\n",
      "Epoch 85/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8155 - val_loss: 3.5905\n",
      "Epoch 86/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8101 - val_loss: 3.5819\n",
      "Epoch 87/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8031 - val_loss: 3.5763\n",
      "Epoch 88/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8063 - val_loss: 3.5738\n",
      "Epoch 89/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7935 - val_loss: 3.5602\n",
      "Epoch 90/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7851 - val_loss: 3.5579\n",
      "Epoch 91/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7800 - val_loss: 3.5509\n",
      "Epoch 92/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7718 - val_loss: 3.5853\n",
      "Epoch 93/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7793 - val_loss: 3.5772\n",
      "Epoch 94/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8019 - val_loss: 3.2092\n",
      "Epoch 95/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7860 - val_loss: 3.2138\n",
      "Epoch 96/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7795 - val_loss: 3.2235\n",
      "Epoch 97/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7797 - val_loss: 3.2139\n",
      "Epoch 98/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7805 - val_loss: 3.1897\n",
      "Epoch 99/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7820 - val_loss: 2.7975\n",
      "Epoch 100/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7778 - val_loss: 3.1912\n",
      "Epoch 101/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7791 - val_loss: 3.2703\n",
      "Epoch 102/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7705 - val_loss: 3.3402\n",
      "Epoch 103/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7670 - val_loss: 3.0346\n",
      "Epoch 104/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7645 - val_loss: 3.0663\n",
      "Epoch 105/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7552 - val_loss: 3.0624\n",
      "Epoch 106/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7527 - val_loss: 3.0629\n",
      "Epoch 107/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7464 - val_loss: 3.0369\n",
      "Epoch 108/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7409 - val_loss: 2.9975\n",
      "Epoch 109/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7332 - val_loss: 2.9768\n",
      "Epoch 110/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7278 - val_loss: 2.9387\n",
      "Epoch 111/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7234 - val_loss: 3.1768\n",
      "Epoch 112/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7296 - val_loss: 3.5281\n",
      "Epoch 113/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7402 - val_loss: 3.4957\n",
      "Epoch 114/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7305 - val_loss: 3.5016\n",
      "Epoch 115/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7350 - val_loss: 3.5041\n",
      "Epoch 116/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7268 - val_loss: 3.5079\n",
      "Epoch 117/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7229 - val_loss: 3.5055\n",
      "Epoch 118/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7197 - val_loss: 3.4790\n",
      "Epoch 119/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7131 - val_loss: 3.4898\n",
      "Epoch 120/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7143 - val_loss: 3.8532\n",
      "Epoch 121/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7050 - val_loss: 3.8464\n",
      "Epoch 122/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7008 - val_loss: 3.8421\n",
      "Epoch 123/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6970 - val_loss: 3.8423\n",
      "Epoch 124/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6919 - val_loss: 3.8373\n",
      "Epoch 125/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6864 - val_loss: 3.8330\n",
      "Epoch 126/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6801 - val_loss: 3.8288\n",
      "Epoch 127/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6839 - val_loss: 3.1112\n",
      "Epoch 128/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6817 - val_loss: 3.0485\n",
      "Epoch 129/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6851 - val_loss: 3.4174\n",
      "Epoch 130/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6899 - val_loss: 3.4822\n",
      "Epoch 131/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6898 - val_loss: 3.6801\n",
      "Epoch 132/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6847 - val_loss: 3.6643\n",
      "Epoch 133/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6832 - val_loss: 3.3885\n",
      "Epoch 134/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6737 - val_loss: 3.2584\n",
      "Epoch 135/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6735 - val_loss: 3.1749\n",
      "Epoch 136/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6642 - val_loss: 3.0577\n",
      "Epoch 137/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6580 - val_loss: 2.9330\n",
      "Epoch 138/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6574 - val_loss: 2.8507\n",
      "Epoch 139/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6536 - val_loss: 2.8970\n",
      "Epoch 140/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6577 - val_loss: 2.9919\n",
      "Epoch 141/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6533 - val_loss: 2.9147\n",
      "Epoch 142/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6476 - val_loss: 3.2416\n",
      "Epoch 143/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6428 - val_loss: 3.1922\n",
      "Epoch 144/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6394 - val_loss: 3.2145\n",
      "Epoch 145/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6376 - val_loss: 3.1869\n",
      "Epoch 146/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6403 - val_loss: 3.1638\n",
      "Epoch 147/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6354 - val_loss: 3.5409\n",
      "Epoch 148/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6272 - val_loss: 3.3097\n",
      "Epoch 149/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6241 - val_loss: 3.4447\n",
      "Epoch 150/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6223 - val_loss: 3.3192\n",
      "Epoch 151/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6230 - val_loss: 3.3045\n",
      "Epoch 152/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6246 - val_loss: 3.1092\n",
      "Epoch 153/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6266 - val_loss: 3.0604\n",
      "Epoch 154/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6213 - val_loss: 3.1225\n",
      "Epoch 155/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6216 - val_loss: 3.5428\n",
      "Epoch 156/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6149 - val_loss: 3.5542\n",
      "Epoch 157/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6129 - val_loss: 3.3312\n",
      "Epoch 158/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6101 - val_loss: 3.6218\n",
      "Epoch 159/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6051 - val_loss: 3.5444\n",
      "Epoch 160/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6086 - val_loss: 3.4137\n",
      "Epoch 161/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5994 - val_loss: 3.3712\n",
      "Epoch 162/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5977 - val_loss: 3.2311\n",
      "Epoch 163/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5989 - val_loss: 3.1265\n",
      "Epoch 164/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5922 - val_loss: 3.4697\n",
      "Epoch 165/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5902 - val_loss: 3.4458\n",
      "Epoch 166/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5845 - val_loss: 3.4341\n",
      "Epoch 167/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5850 - val_loss: 3.4353\n",
      "Epoch 168/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5843 - val_loss: 3.4388\n",
      "Epoch 169/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5808 - val_loss: 3.4602\n",
      "Epoch 170/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5850 - val_loss: 3.7500\n",
      "Epoch 171/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5882 - val_loss: 3.7563\n",
      "Epoch 172/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5949 - val_loss: 3.7602\n",
      "Epoch 173/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5979 - val_loss: 3.7542\n",
      "Epoch 174/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5944 - val_loss: 3.4871\n",
      "Epoch 175/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5967 - val_loss: 3.3851\n",
      "Epoch 176/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5955 - val_loss: 3.7321\n",
      "Epoch 177/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5902 - val_loss: 3.7271\n",
      "Epoch 178/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5872 - val_loss: 3.7300\n",
      "Epoch 179/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5849 - val_loss: 3.7312\n",
      "Epoch 180/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5822 - val_loss: 3.7252\n",
      "Epoch 181/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5807 - val_loss: 3.7261\n",
      "Epoch 182/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5817 - val_loss: 3.7247\n",
      "Epoch 183/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5791 - val_loss: 3.7279\n",
      "Epoch 184/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5848 - val_loss: 3.7284\n",
      "Epoch 185/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5740 - val_loss: 3.7243\n",
      "Epoch 186/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5712 - val_loss: 3.7209\n",
      "Epoch 187/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5704 - val_loss: 3.3723\n",
      "Epoch 188/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5722 - val_loss: 3.3493\n",
      "Epoch 189/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5673 - val_loss: 3.3434\n",
      "Epoch 190/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5694 - val_loss: 3.3592\n",
      "Epoch 191/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5643 - val_loss: 3.3982\n",
      "Epoch 192/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5639 - val_loss: 3.4319\n",
      "Epoch 193/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5693 - val_loss: 3.4005\n",
      "Epoch 194/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5737 - val_loss: 3.1736\n",
      "Epoch 195/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5763 - val_loss: 3.5293\n",
      "Epoch 196/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5757 - val_loss: 3.5450\n",
      "Epoch 197/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5722 - val_loss: 3.5414\n",
      "Epoch 198/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5710 - val_loss: 3.4819\n",
      "Epoch 199/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5727 - val_loss: 3.4141\n",
      "Epoch 200/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5740 - val_loss: 3.3565\n",
      "Epoch 201/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5703 - val_loss: 3.3523\n",
      "Epoch 202/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5718 - val_loss: 3.3562\n",
      "Epoch 203/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5683 - val_loss: 3.3887\n",
      "Epoch 204/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5644 - val_loss: 3.1393\n",
      "Epoch 205/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5719 - val_loss: 3.0973\n",
      "Epoch 206/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5750 - val_loss: 2.8598\n",
      "Epoch 207/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5717 - val_loss: 1.0591\n",
      "Epoch 208/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5693 - val_loss: 2.1374\n",
      "Epoch 209/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5692 - val_loss: 2.7632\n",
      "Epoch 210/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5704 - val_loss: 2.7647\n",
      "Epoch 211/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5745 - val_loss: inf\n",
      "Epoch 212/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.9157 - val_loss: 5.5615\n",
      "Epoch 213/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4631 - val_loss: inf\n",
      "Epoch 214/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6504 - val_loss: inf\n",
      "Epoch 215/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6538 - val_loss: inf\n",
      "Epoch 216/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6703 - val_loss: inf\n",
      "Epoch 217/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6887 - val_loss: inf\n",
      "Epoch 218/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7032 - val_loss: inf\n",
      "Epoch 219/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7340 - val_loss: inf\n",
      "Epoch 220/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7373 - val_loss: inf\n",
      "Epoch 221/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7341 - val_loss: inf\n",
      "Epoch 222/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7254 - val_loss: inf\n",
      "Epoch 223/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7277 - val_loss: inf\n",
      "Epoch 224/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7211 - val_loss: 12.8698\n",
      "Epoch 225/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7182 - val_loss: 8.3351\n",
      "Epoch 226/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7065 - val_loss: 6.6922\n",
      "Epoch 227/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7022 - val_loss: 5.6710\n",
      "Epoch 228/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6953 - val_loss: 4.6627\n",
      "Epoch 229/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6898 - val_loss: 4.5234\n",
      "Epoch 230/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6844 - val_loss: 4.2638\n",
      "Epoch 231/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6842 - val_loss: 3.6221\n",
      "Epoch 232/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6798 - val_loss: 3.2713\n",
      "Epoch 233/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6719 - val_loss: 3.3834\n",
      "Epoch 234/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6672 - val_loss: 3.7300\n",
      "Epoch 235/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6619 - val_loss: 3.8810\n",
      "Epoch 236/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6621 - val_loss: 3.9965\n",
      "Epoch 237/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6558 - val_loss: 3.9890\n",
      "Epoch 238/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6546 - val_loss: 3.4652\n",
      "Epoch 239/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6496 - val_loss: 3.0147\n",
      "Epoch 240/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6467 - val_loss: 3.2144\n",
      "Epoch 241/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6431 - val_loss: 3.9314\n",
      "Epoch 242/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6474 - val_loss: 4.6346\n",
      "Epoch 243/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6408 - val_loss: 2.7445\n",
      "Epoch 244/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6348 - val_loss: 2.4899\n",
      "Epoch 245/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6311 - val_loss: 2.9187\n",
      "Epoch 246/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6267 - val_loss: 2.7077\n",
      "Epoch 247/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6272 - val_loss: 2.9765\n",
      "Epoch 248/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6219 - val_loss: 2.9696\n",
      "Epoch 249/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6261 - val_loss: 3.4053\n",
      "Epoch 250/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6179 - val_loss: 3.7724\n",
      "Epoch 251/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6145 - val_loss: 3.7690\n",
      "Epoch 252/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6135 - val_loss: 3.7720\n",
      "Epoch 253/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6115 - val_loss: 3.7692\n",
      "Epoch 254/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6094 - val_loss: 3.7644\n",
      "Epoch 255/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6111 - val_loss: 3.3856\n",
      "Epoch 256/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6160 - val_loss: 3.4076\n",
      "Epoch 257/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6191 - val_loss: 3.4317\n",
      "Epoch 258/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6114 - val_loss: 3.4373\n",
      "Epoch 259/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6089 - val_loss: 3.4477\n",
      "Epoch 260/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6090 - val_loss: 3.4462\n",
      "Epoch 261/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6099 - val_loss: 3.4562\n",
      "Epoch 262/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6088 - val_loss: 3.4173\n",
      "Epoch 263/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6038 - val_loss: 3.4010\n",
      "Epoch 264/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5996 - val_loss: 3.3909\n",
      "Epoch 265/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5916 - val_loss: 3.3894\n",
      "Epoch 266/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5955 - val_loss: 3.3956\n",
      "Epoch 267/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5964 - val_loss: 3.3863\n",
      "Epoch 268/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6006 - val_loss: 3.3833\n",
      "Epoch 269/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5887 - val_loss: 3.0406\n",
      "Epoch 270/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5854 - val_loss: 3.0099\n",
      "Epoch 271/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5880 - val_loss: 3.0139\n",
      "Epoch 272/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5904 - val_loss: 3.0085\n",
      "Epoch 273/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5823 - val_loss: 3.0056\n",
      "Epoch 274/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5788 - val_loss: 2.9927\n",
      "Epoch 275/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5833 - val_loss: 2.9834\n",
      "Epoch 276/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5774 - val_loss: 2.9835\n",
      "Epoch 277/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5727 - val_loss: 2.9919\n",
      "Epoch 278/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5731 - val_loss: 3.0520\n",
      "Epoch 279/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5706 - val_loss: 3.0338\n",
      "Epoch 280/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5745 - val_loss: 2.9778\n",
      "Epoch 281/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5722 - val_loss: 2.9737\n",
      "Epoch 282/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5706 - val_loss: 2.9666\n",
      "Epoch 283/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5713 - val_loss: 2.9731\n",
      "Epoch 284/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5675 - val_loss: 3.0588\n",
      "Epoch 285/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5757 - val_loss: 2.9489\n",
      "Epoch 286/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5780 - val_loss: 7.9196\n",
      "Epoch 287/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5824 - val_loss: inf\n",
      "Epoch 288/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5807 - val_loss: inf\n",
      "Epoch 289/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5870 - val_loss: 7.8641\n",
      "Epoch 290/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5951 - val_loss: 4.4442\n",
      "Epoch 291/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5840 - val_loss: 2.6646\n",
      "Epoch 292/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5843 - val_loss: 1.5714\n",
      "Epoch 293/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5810 - val_loss: 2.1282\n",
      "Epoch 294/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5852 - val_loss: 2.7785\n",
      "Epoch 295/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5769 - val_loss: 3.1254\n",
      "Epoch 296/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5800 - val_loss: 3.1126\n",
      "Epoch 297/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5788 - val_loss: 3.0816\n",
      "Epoch 298/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5796 - val_loss: 3.0271\n",
      "Epoch 299/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5791 - val_loss: 3.3903\n",
      "Epoch 300/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5750 - val_loss: 3.3837\n",
      "Epoch 301/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5725 - val_loss: 3.3780\n",
      "Epoch 302/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5712 - val_loss: 3.3784\n",
      "Epoch 303/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5653 - val_loss: 3.3885\n",
      "Epoch 304/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5682 - val_loss: 3.3850\n",
      "Epoch 305/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5605 - val_loss: 3.3804\n",
      "Epoch 306/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5587 - val_loss: 3.3772\n",
      "Epoch 307/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5554 - val_loss: 3.3897\n",
      "Epoch 308/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5545 - val_loss: 3.4036\n",
      "Epoch 309/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5525 - val_loss: 3.3894\n",
      "Epoch 310/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5479 - val_loss: 3.3627\n",
      "Epoch 311/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5476 - val_loss: 3.3516\n",
      "Epoch 312/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5470 - val_loss: 3.3616\n",
      "Epoch 313/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5463 - val_loss: 3.3706\n",
      "Epoch 314/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5440 - val_loss: 3.3457\n",
      "Epoch 315/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5456 - val_loss: 3.3362\n",
      "Epoch 316/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5466 - val_loss: 2.5916\n",
      "Epoch 317/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5502 - val_loss: 2.5899\n",
      "Epoch 318/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5473 - val_loss: 2.6571\n",
      "Epoch 319/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5506 - val_loss: 2.7629\n",
      "Epoch 320/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5439 - val_loss: 3.2307\n",
      "Epoch 321/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5464 - val_loss: 3.2697\n",
      "Epoch 322/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5419 - val_loss: 3.2403\n",
      "Epoch 323/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5414 - val_loss: 3.2542\n",
      "Epoch 324/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5467 - val_loss: 3.2427\n",
      "Epoch 325/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5455 - val_loss: 3.2323\n",
      "Epoch 326/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5425 - val_loss: 3.1775\n",
      "Epoch 327/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5401 - val_loss: 3.1866\n",
      "Epoch 328/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5432 - val_loss: 2.5669\n",
      "Epoch 329/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5423 - val_loss: 1.4002\n",
      "Epoch 330/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5442 - val_loss: 1.6679\n",
      "Epoch 331/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5476 - val_loss: 2.0886\n",
      "Epoch 332/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5454 - val_loss: 1.7602\n",
      "Epoch 333/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5431 - val_loss: 1.5579\n",
      "Epoch 334/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5424 - val_loss: 1.8839\n",
      "Epoch 335/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5418 - val_loss: 2.6299\n",
      "Epoch 336/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5426 - val_loss: 2.9527\n",
      "Epoch 337/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5430 - val_loss: 3.3107\n",
      "Epoch 338/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5449 - val_loss: 3.3212\n",
      "Epoch 339/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5424 - val_loss: 3.6829\n",
      "Epoch 340/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5382 - val_loss: 3.7034\n",
      "Epoch 341/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5356 - val_loss: 3.3439\n",
      "Epoch 342/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5379 - val_loss: 3.3415\n",
      "Epoch 343/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5374 - val_loss: 3.3940\n",
      "Epoch 344/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5325 - val_loss: 3.5892\n",
      "Epoch 345/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5340 - val_loss: 3.6007\n",
      "Epoch 346/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5334 - val_loss: 3.2847\n",
      "Epoch 347/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5336 - val_loss: 3.6894\n",
      "Epoch 348/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5343 - val_loss: 3.7307\n",
      "Epoch 349/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5341 - val_loss: 3.7767\n",
      "Epoch 350/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5376 - val_loss: 3.8930\n",
      "Epoch 351/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5359 - val_loss: 4.0027\n",
      "Epoch 352/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5294 - val_loss: 4.4750\n",
      "Epoch 353/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5291 - val_loss: 4.1391\n",
      "Epoch 354/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5272 - val_loss: 4.1153\n",
      "Epoch 355/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5295 - val_loss: 4.0392\n",
      "Epoch 356/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5274 - val_loss: 3.9345\n",
      "Epoch 357/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5352 - val_loss: 4.1667\n",
      "Epoch 358/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5290 - val_loss: 4.1200\n",
      "Epoch 359/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5276 - val_loss: 3.6932\n",
      "Epoch 360/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5269 - val_loss: 4.0376\n",
      "Epoch 361/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5240 - val_loss: 3.9983\n",
      "Epoch 362/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5298 - val_loss: 3.9429\n",
      "Epoch 363/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5319 - val_loss: 3.8544\n",
      "Epoch 364/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5332 - val_loss: 3.7765\n",
      "Epoch 365/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5245 - val_loss: 2.6494\n",
      "Epoch 366/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5237 - val_loss: 1.1503\n",
      "Epoch 367/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5250 - val_loss: 1.2342\n",
      "Epoch 368/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5267 - val_loss: 1.2565\n",
      "Epoch 369/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5259 - val_loss: 1.1558\n",
      "Epoch 370/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5258 - val_loss: 2.2104\n",
      "Epoch 371/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5236 - val_loss: 2.9128\n",
      "Epoch 372/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5221 - val_loss: 2.8468\n",
      "Epoch 373/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5243 - val_loss: 2.7616\n",
      "Epoch 374/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5249 - val_loss: 2.7399\n",
      "Epoch 375/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5192 - val_loss: 2.6690\n",
      "Epoch 376/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5243 - val_loss: 2.6011\n",
      "Epoch 377/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5207 - val_loss: 2.5480\n",
      "Epoch 378/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5160 - val_loss: 2.5414\n",
      "Epoch 379/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5176 - val_loss: 2.5585\n",
      "Epoch 380/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5145 - val_loss: 2.5512\n",
      "Epoch 381/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5156 - val_loss: 2.5546\n",
      "Epoch 382/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5153 - val_loss: 3.2978\n",
      "Epoch 383/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5141 - val_loss: 3.3261\n",
      "Epoch 384/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5137 - val_loss: 2.6647\n",
      "Epoch 385/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5147 - val_loss: 2.9541\n",
      "Epoch 386/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5146 - val_loss: 2.9426\n",
      "Epoch 387/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5094 - val_loss: 2.9385\n",
      "Epoch 388/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5127 - val_loss: 2.9423\n",
      "Epoch 389/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5152 - val_loss: 3.3175\n",
      "Epoch 390/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5172 - val_loss: 3.2862\n",
      "Epoch 391/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5158 - val_loss: 3.2881\n",
      "Epoch 392/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5129 - val_loss: 3.6686\n",
      "Epoch 393/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5157 - val_loss: 3.6763\n",
      "Epoch 394/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5161 - val_loss: 3.6777\n",
      "Epoch 395/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5123 - val_loss: 3.6892\n",
      "Epoch 396/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5120 - val_loss: 3.6856\n",
      "Epoch 397/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5239 - val_loss: 1.9523\n",
      "Epoch 398/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5203 - val_loss: 2.6252\n",
      "Epoch 399/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5198 - val_loss: 2.9259\n",
      "Epoch 400/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5178 - val_loss: 2.9742\n",
      "Epoch 401/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5170 - val_loss: 2.7437\n",
      "Epoch 402/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5153 - val_loss: 2.4365\n",
      "Epoch 403/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5159 - val_loss: 2.2209\n",
      "Epoch 404/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5153 - val_loss: 2.4719\n",
      "Epoch 405/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5177 - val_loss: 3.3135\n",
      "Epoch 406/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5195 - val_loss: 3.2502\n",
      "Epoch 407/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5193 - val_loss: 2.3097\n",
      "Epoch 408/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5195 - val_loss: 1.8676\n",
      "Epoch 409/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5167 - val_loss: 2.3016\n",
      "Epoch 410/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5190 - val_loss: 2.0205\n",
      "Epoch 411/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5192 - val_loss: 2.2638\n",
      "Epoch 412/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5160 - val_loss: 2.9481\n",
      "Epoch 413/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5161 - val_loss: 2.9321\n",
      "Epoch 414/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5157 - val_loss: 3.2988\n",
      "Epoch 415/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5149 - val_loss: 3.2865\n",
      "Epoch 416/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5165 - val_loss: 3.2863\n",
      "Epoch 417/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5178 - val_loss: 2.9174\n",
      "Epoch 418/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5187 - val_loss: 3.2906\n",
      "Epoch 419/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5155 - val_loss: 3.2859\n",
      "Epoch 420/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5127 - val_loss: 3.2846\n",
      "Epoch 421/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5107 - val_loss: 2.9212\n",
      "Epoch 422/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5101 - val_loss: 1.8279\n",
      "Epoch 423/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5122 - val_loss: 1.5110\n",
      "Epoch 424/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5141 - val_loss: 1.7511\n",
      "Epoch 425/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5135 - val_loss: 1.9714\n",
      "Epoch 426/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5114 - val_loss: 1.7777\n",
      "Epoch 427/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5138 - val_loss: 2.5335\n",
      "Epoch 428/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5203 - val_loss: 2.5514\n",
      "Epoch 429/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5095 - val_loss: 2.5585\n",
      "Epoch 430/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5115 - val_loss: 2.8582\n",
      "Epoch 431/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5126 - val_loss: 2.7922\n",
      "Epoch 432/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5103 - val_loss: 2.5082\n",
      "Epoch 433/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5104 - val_loss: 2.4281\n",
      "Epoch 434/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5019 - val_loss: 2.9374\n",
      "Epoch 435/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5065 - val_loss: 3.1235\n",
      "Epoch 436/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5067 - val_loss: 4.1881\n",
      "Epoch 437/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5073 - val_loss: 4.1467\n",
      "Epoch 438/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5059 - val_loss: 4.3208\n",
      "Epoch 439/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5039 - val_loss: 3.5892\n",
      "Epoch 440/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5034 - val_loss: 2.7367\n",
      "Epoch 441/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4999 - val_loss: 2.3414\n",
      "Epoch 442/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5003 - val_loss: 2.1590\n",
      "Epoch 443/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5100 - val_loss: 3.9420\n",
      "Epoch 444/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5090 - val_loss: 4.5889\n",
      "Epoch 445/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5082 - val_loss: 4.2013\n",
      "Epoch 446/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5066 - val_loss: 3.5059\n",
      "Epoch 447/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5046 - val_loss: 3.6528\n",
      "Epoch 448/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5051 - val_loss: 4.9190\n",
      "Epoch 449/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5106 - val_loss: 2.8981\n",
      "Epoch 450/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5070 - val_loss: 2.2990\n",
      "Epoch 451/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5130 - val_loss: 2.1975\n",
      "Epoch 452/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5212 - val_loss: 2.5639\n",
      "Epoch 453/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5276 - val_loss: 3.2849\n",
      "Epoch 454/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5380 - val_loss: 3.8720\n",
      "Epoch 455/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5476 - val_loss: 5.7915\n",
      "Epoch 456/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5654 - val_loss: 3.5192\n",
      "Epoch 457/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5657 - val_loss: 10.5930\n",
      "Epoch 458/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5742 - val_loss: inf\n",
      "Epoch 459/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5689 - val_loss: inf\n",
      "Epoch 460/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5722 - val_loss: inf\n",
      "Epoch 461/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5673 - val_loss: inf\n",
      "Epoch 462/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5687 - val_loss: 13.1741\n",
      "Epoch 463/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5628 - val_loss: 6.7131\n",
      "Epoch 464/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5683 - val_loss: 4.0105\n",
      "Epoch 465/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5633 - val_loss: 2.6926\n",
      "Epoch 466/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5579 - val_loss: 2.0855\n",
      "Epoch 467/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5526 - val_loss: 1.9673\n",
      "Epoch 468/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5412 - val_loss: 2.6149\n",
      "Epoch 469/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5417 - val_loss: 2.5887\n",
      "Epoch 470/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5379 - val_loss: 3.3422\n",
      "Epoch 471/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5362 - val_loss: 3.3296\n",
      "Epoch 472/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5324 - val_loss: 3.3093\n",
      "Epoch 473/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5313 - val_loss: 3.2925\n",
      "Epoch 474/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5274 - val_loss: 3.2901\n",
      "Epoch 475/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5320 - val_loss: 3.2893\n",
      "Epoch 476/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5225 - val_loss: 3.2982\n",
      "Epoch 477/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5194 - val_loss: 3.2975\n",
      "Epoch 478/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5255 - val_loss: 3.3046\n",
      "Epoch 479/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5160 - val_loss: 3.3074\n",
      "Epoch 480/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5170 - val_loss: 3.3113\n",
      "Epoch 481/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5159 - val_loss: 2.9441\n",
      "Epoch 482/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5152 - val_loss: 2.9186\n",
      "Epoch 483/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5106 - val_loss: 2.9548\n",
      "Epoch 484/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5131 - val_loss: 2.9771\n",
      "Epoch 485/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5108 - val_loss: 2.6314\n",
      "Epoch 486/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5066 - val_loss: 2.6621\n",
      "Epoch 487/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5090 - val_loss: 2.6788\n",
      "Epoch 488/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5095 - val_loss: 2.6755\n",
      "Epoch 489/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5051 - val_loss: 2.7060\n",
      "Epoch 490/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5096 - val_loss: 3.1084\n",
      "Epoch 491/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5052 - val_loss: 3.1394\n",
      "Epoch 492/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5037 - val_loss: 3.5406\n",
      "Epoch 493/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5020 - val_loss: 3.5718\n",
      "Epoch 494/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4985 - val_loss: 3.6191\n",
      "Epoch 495/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5023 - val_loss: 3.3201\n",
      "Epoch 496/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5019 - val_loss: 3.3436\n",
      "Epoch 497/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4995 - val_loss: 3.0821\n",
      "Epoch 498/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5065 - val_loss: 3.4074\n",
      "Epoch 499/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4968 - val_loss: 3.3593\n",
      "Epoch 500/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5015 - val_loss: 3.3086\n",
      "Epoch 501/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5057 - val_loss: 2.9609\n",
      "Epoch 502/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5039 - val_loss: 2.8996\n",
      "Epoch 503/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4999 - val_loss: 3.1723\n",
      "Epoch 504/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4994 - val_loss: 3.1267\n",
      "Epoch 505/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5008 - val_loss: 3.0789\n",
      "Epoch 506/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4992 - val_loss: 3.4187\n",
      "Epoch 507/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4960 - val_loss: 3.1040\n",
      "Epoch 508/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4928 - val_loss: 3.3593\n",
      "Epoch 509/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4915 - val_loss: 3.3422\n",
      "Epoch 510/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4887 - val_loss: 3.3294\n",
      "Epoch 511/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4919 - val_loss: 3.3117\n",
      "Epoch 512/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4921 - val_loss: 3.2988\n",
      "Epoch 513/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4901 - val_loss: 3.2910\n",
      "Epoch 514/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4879 - val_loss: 3.3233\n",
      "Epoch 515/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4979 - val_loss: 3.4304\n",
      "Epoch 516/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5011 - val_loss: 3.4775\n",
      "Epoch 517/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4929 - val_loss: 3.4886\n",
      "Epoch 518/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4977 - val_loss: 3.4971\n",
      "Epoch 519/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4962 - val_loss: 3.5144\n",
      "Epoch 520/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4950 - val_loss: 3.5090\n",
      "Epoch 521/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4992 - val_loss: 3.4678\n",
      "Epoch 522/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4935 - val_loss: 3.4652\n",
      "Epoch 523/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4913 - val_loss: 3.0994\n",
      "Epoch 524/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4902 - val_loss: 3.1026\n",
      "Epoch 525/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4941 - val_loss: 3.1345\n",
      "Epoch 526/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4910 - val_loss: 3.1691\n",
      "Epoch 527/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4952 - val_loss: 3.2043\n",
      "Epoch 528/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4907 - val_loss: 3.0999\n",
      "Epoch 529/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4899 - val_loss: 3.0590\n",
      "Epoch 530/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4852 - val_loss: 3.0207\n",
      "Epoch 531/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4832 - val_loss: 2.9795\n",
      "Epoch 532/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4784 - val_loss: 2.9535\n",
      "Epoch 533/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4799 - val_loss: 2.9440\n",
      "Epoch 534/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4771 - val_loss: 2.8984\n",
      "Epoch 535/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4782 - val_loss: 3.2601\n",
      "Epoch 536/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4757 - val_loss: 3.2669\n",
      "Epoch 537/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4766 - val_loss: 3.2805\n",
      "Epoch 538/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4812 - val_loss: 3.6510\n",
      "Epoch 539/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4809 - val_loss: 3.6489\n",
      "Epoch 540/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4826 - val_loss: 3.6506\n",
      "Epoch 541/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4808 - val_loss: 3.6535\n",
      "Epoch 542/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4824 - val_loss: 3.6432\n",
      "Epoch 543/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4819 - val_loss: 3.6419\n",
      "Epoch 544/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4838 - val_loss: 3.6402\n",
      "Epoch 545/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4842 - val_loss: 3.6374\n",
      "Epoch 546/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4879 - val_loss: 3.6334\n",
      "Epoch 547/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5025 - val_loss: 2.2117\n",
      "Epoch 548/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5077 - val_loss: inf\n",
      "Epoch 549/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5171 - val_loss: inf\n",
      "Epoch 550/550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5249 - val_loss: inf\n"
     ]
    }
   ],
   "source": [
    "history=autoencoder.fit(X_train,X_train,validation_data=(X_test, X_test),batch_size=128,epochs=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVz0lEQVR4nO3dd3xTVf8H8M9N0qRNd0snlLL3lCUgQ0VZIoiTh0cBFRyg4pZHRcCBPi4eUXGDC3H8BFEZAgICInsvAUvLKgW6V5pxf3+c3Jt7s5s2zU3yfb9efaW5uUlO0jT3e7/ne87heJ7nQQghhBAShFSBbgAhhBBCiK8okCGEEEJI0KJAhhBCCCFBiwIZQgghhAQtCmQIIYQQErQokCGEEEJI0KJAhhBCCCFBiwIZQgghhAQtCmQIIYQQErQokCHETyZOnIhmzZr5dN9Zs2aB47j6bZDCnDp1ChzHYdGiRQ3+3BzHYdasWeL1RYsWgeM4nDp1yuN9mzVrhokTJ9Zre+ryWSEk3FEgQ8IOx3Fe/WzYsCHQTQ17Dz/8MDiOw4kTJ1zu8+yzz4LjOOzfv78BW1Z7586dw6xZs7B3795AN0UkBJNvvPFGoJtCiM80gW4AIQ3tyy+/lF3/4osvsGbNGoft7du3r9PzfPzxx7BYLD7d97nnnsMzzzxTp+cPBePHj8f8+fOxePFizJw50+k+33zzDTp37owuXbr4/Dx33nkn7rjjDuh0Op8fw5Nz585h9uzZaNasGbp16ya7rS6fFULCHQUyJOz8+9//ll3/66+/sGbNGoft9iorK6HX671+noiICJ/aBwAajQYaDf179unTB61atcI333zjNJDZunUrcnJy8Oqrr9bpedRqNdRqdZ0eoy7q8lkhJNxR1xIhTgwePBidOnXCrl27MHDgQOj1evznP/8BAPz0008YOXIkMjMzodPp0LJlS7z44oswm82yx7Cve5Cm8T/66CO0bNkSOp0OvXr1wo4dO2T3dVYjw3Ecpk2bhmXLlqFTp07Q6XTo2LEjVq1a5dD+DRs2oGfPnoiMjETLli3x4Ycfel13s2nTJtx6661o2rQpdDodsrKy8Oijj6Kqqsrh9cXExODs2bMYM2YMYmJikJKSgieeeMLhvSguLsbEiRMRHx+PhIQETJgwAcXFxR7bArCszNGjR7F7926H2xYvXgyO4zBu3DjU1NRg5syZ6NGjB+Lj4xEdHY0BAwZg/fr1Hp/DWY0Mz/N46aWX0KRJE+j1elx99dU4dOiQw30LCwvxxBNPoHPnzoiJiUFcXByGDx+Offv2ifts2LABvXr1AgBMmjRJ7L4U6oOc1chUVFTg8ccfR1ZWFnQ6Hdq2bYs33ngDPM/L9qvN58JXBQUFuOeee5CWlobIyEh07doVn3/+ucN+S5YsQY8ePRAbG4u4uDh07twZ//vf/8TbjUYjZs+ejdatWyMyMhLJycm46qqrsGbNmnprKwk/dMpHiAuXL1/G8OHDcccdd+Df//430tLSALCDXkxMDB577DHExMTg999/x8yZM1FaWorXX3/d4+MuXrwYZWVluO+++8BxHP773/9i7Nix+OeffzyemW/evBk//vgjHnzwQcTGxuKdd97BzTffjLy8PCQnJwMA9uzZg2HDhiEjIwOzZ8+G2WzGnDlzkJKS4tXr/v7771FZWYkHHngAycnJ2L59O+bPn48zZ87g+++/l+1rNpsxdOhQ9OnTB2+88QbWrl2LN998Ey1btsQDDzwAgAUEo0ePxubNm3H//fejffv2WLp0KSZMmOBVe8aPH4/Zs2dj8eLFuOKKK2TP/d1332HAgAFo2rQpLl26hE8++QTjxo3D5MmTUVZWhk8//RRDhw7F9u3bHbpzPJk5cyZeeukljBgxAiNGjMDu3btx/fXXo6amRrbfP//8g2XLluHWW29F8+bNceHCBXz44YcYNGgQDh8+jMzMTLRv3x5z5szBzJkzMWXKFAwYMAAA0K9fP6fPzfM8brzxRqxfvx733HMPunXrhtWrV+PJJ5/E2bNn8fbbb8v29+Zz4auqqioMHjwYJ06cwLRp09C8eXN8//33mDhxIoqLi/HII48AANasWYNx48bh2muvxWuvvQYAOHLkCLZs2SLuM2vWLMydOxf33nsvevfujdLSUuzcuRO7d+/GddddV6d2kjDGExLmpk6dytv/KwwaNIgHwH/wwQcO+1dWVjpsu++++3i9Xs9XV1eL2yZMmMBnZ2eL13NycngAfHJyMl9YWChu/+mnn3gA/M8//yxue+GFFxzaBIDXarX8iRMnxG379u3jAfDz588Xt40aNYrX6/X82bNnxW3Hjx/nNRqNw2M64+z1zZ07l+c4js/NzZW9PgD8nDlzZPt2796d79Gjh3h92bJlPAD+v//9r7jNZDLxAwYM4AHwCxcu9NimXr168U2aNOHNZrO4bdWqVTwA/sMPPxQf02AwyO5XVFTEp6Wl8XfffbdsOwD+hRdeEK8vXLiQB8Dn5OTwPM/zBQUFvFar5UeOHMlbLBZxv//85z88AH7ChAniturqalm7eJ79rXU6ney92bFjh8vXa/9ZEd6zl156SbbfLbfcwnMcJ/sMePu5cEb4TL7++usu95k3bx4PgP/qq6/EbTU1NXzfvn35mJgYvrS0lOd5nn/kkUf4uLg43mQyuXysrl278iNHjnTbJkJqi7qWCHFBp9Nh0qRJDtujoqLE38vKynDp0iUMGDAAlZWVOHr0qMfHvf3225GYmCheF87O//nnH4/3HTJkCFq2bCle79KlC+Li4sT7ms1mrF27FmPGjEFmZqa4X6tWrTB8+HCPjw/IX19FRQUuXbqEfv36ged57Nmzx2H/+++/X3Z9wIABsteyYsUKaDQaMUMDsJqUhx56yKv2AKyu6cyZM/jjjz/EbYsXL4ZWq8Wtt94qPqZWqwUAWCwWFBYWwmQyoWfPnk67pdxZu3Ytampq8NBDD8m646ZPn+6wr06ng0rFvkrNZjMuX76MmJgYtG3bttbPK1ixYgXUajUefvhh2fbHH38cPM9j5cqVsu2ePhd1sWLFCqSnp2PcuHHitoiICDz88MMoLy/Hxo0bAQAJCQmoqKhw202UkJCAQ4cO4fjx43VuFyECCmQIcaFx48bigVHq0KFDuOmmmxAfH4+4uDikpKSIhcIlJSUeH7dp06ay60JQU1RUVOv7CvcX7ltQUICqqiq0atXKYT9n25zJy8vDxIkTkZSUJNa9DBo0CIDj64uMjHTospK2BwByc3ORkZGBmJgY2X5t27b1qj0AcMcdd0CtVmPx4sUAgOrqaixduhTDhw+XBYWff/45unTpItZfpKSk4Ndff/Xq7yKVm5sLAGjdurVse0pKiuz5ABY0vf3222jdujV0Oh0aNWqElJQU7N+/v9bPK33+zMxMxMbGyrYLI+mE9gk8fS7qIjc3F61btxaDNVdtefDBB9GmTRsMHz4cTZo0wd133+1QpzNnzhwUFxejTZs26Ny5M5588knFD5snykeBDCEuSDMTguLiYgwaNAj79u3DnDlz8PPPP2PNmjViTYA3Q2hdjY7h7Yo46/u+3jCbzbjuuuvw66+/4umnn8ayZcuwZs0asSjV/vU11Eif1NRUXHfddfi///s/GI1G/PzzzygrK8P48ePFfb766itMnDgRLVu2xKeffopVq1ZhzZo1uOaaa/w6tPmVV17BY489hoEDB+Krr77C6tWrsWbNGnTs2LHBhlT7+3PhjdTUVOzduxfLly8X63uGDx8uq4UaOHAgTp48ic8++wydOnXCJ598giuuuAKffPJJg7WThB4q9iWkFjZs2IDLly/jxx9/xMCBA8XtOTk5AWyVTWpqKiIjI51OIOduUjnBgQMH8Pfff+Pzzz/HXXfdJW6vy6iS7OxsrFu3DuXl5bKszLFjx2r1OOPHj8eqVauwcuVKLF68GHFxcRg1apR4+w8//IAWLVrgxx9/lHUHvfDCCz61GQCOHz+OFi1aiNsvXrzokOX44YcfcPXVV+PTTz+VbS8uLkajRo3E67WZqTk7Oxtr165FWVmZLCsjdF0K7WsI2dnZ2L9/PywWiywr46wtWq0Wo0aNwqhRo2CxWPDggw/iww8/xPPPPy9mBJOSkjBp0iRMmjQJ5eXlGDhwIGbNmoV77723wV4TCS2UkSGkFoQzX+mZbk1NDd5///1ANUlGrVZjyJAhWLZsGc6dOyduP3HihENdhav7A/LXx/O8bAhtbY0YMQImkwkLFiwQt5nNZsyfP79WjzNmzBjo9Xq8//77WLlyJcaOHYvIyEi3bd+2bRu2bt1a6zYPGTIEERERmD9/vuzx5s2b57CvWq12yHx8//33OHv2rGxbdHQ0AHg17HzEiBEwm8149913ZdvffvttcBzndb1TfRgxYgTy8/Px7bffittMJhPmz5+PmJgYsdvx8uXLsvupVCpxkkKDweB0n5iYGLRq1Uq8nRBfUEaGkFro168fEhMTMWHCBHH6/C+//LJBU/iezJo1C7/99hv69++PBx54QDwgdurUyeP0+O3atUPLli3xxBNP4OzZs4iLi8P//d//1anWYtSoUejfvz+eeeYZnDp1Ch06dMCPP/5Y6/qRmJgYjBkzRqyTkXYrAcANN9yAH3/8ETfddBNGjhyJnJwcfPDBB+jQoQPKy8tr9VzCfDhz587FDTfcgBEjRmDPnj1YuXKlLMsiPO+cOXMwadIk9OvXDwcOHMDXX38ty+QAQMuWLZGQkIAPPvgAsbGxiI6ORp8+fdC8eXOH5x81ahSuvvpqPPvsszh16hS6du2K3377DT/99BOmT58uK+ytD+vWrUN1dbXD9jFjxmDKlCn48MMPMXHiROzatQvNmjXDDz/8gC1btmDevHlixujee+9FYWEhrrnmGjRp0gS5ubmYP38+unXrJtbTdOjQAYMHD0aPHj2QlJSEnTt34ocffsC0adPq9fWQMBOYwVKEKIer4dcdO3Z0uv+WLVv4K6+8ko+KiuIzMzP5p556il+9ejUPgF+/fr24n6vh186GusJuOLCr4ddTp051uG92drZsODDP8/y6dev47t2781qtlm/ZsiX/ySef8I8//jgfGRnp4l2wOXz4MD9kyBA+JiaGb9SoET958mRxOK906PCECRP46Ohoh/s7a/vly5f5O++8k4+Li+Pj4+P5O++8k9+zZ4/Xw68Fv/76Kw+Az8jIcBjybLFY+FdeeYXPzs7mdTod3717d/6XX35x+DvwvOfh1zzP82azmZ89ezafkZHBR0VF8YMHD+YPHjzo8H5XV1fzjz/+uLhf//79+a1bt/KDBg3iBw0aJHven376ie/QoYM4FF547c7aWFZWxj/66KN8ZmYmHxERwbdu3Zp//fXXZcPBhdfi7efCnvCZdPXz5Zdf8jzP8xcuXOAnTZrEN2rUiNdqtXznzp0d/m4//PADf/311/Opqam8VqvlmzZtyt933338+fPnxX1eeuklvnfv3nxCQgIfFRXFt2vXjn/55Zf5mpoat+0kxB2O5xV0KkkI8ZsxY8bQ0FdCSMihGhlCQpD9cgLHjx/HihUrMHjw4MA0iBBC/IQyMoSEoIyMDEycOBEtWrRAbm4uFixYAIPBgD179jjMjUIIIcGMin0JCUHDhg3DN998g/z8fOh0OvTt2xevvPIKBTGEkJBDGRlCCCGEBC2qkSGEEEJI0KJAhhBCCCFBK+RrZCwWC86dO4fY2NhaTRFOCCGEkMDheR5lZWXIzMx0WLRUKuQDmXPnziErKyvQzSCEEEKID06fPo0mTZq4vD3kAxlh+uzTp08jLi4uwK0hhBBCiDdKS0uRlZUlWzjVmZAPZITupLi4OApkCCGEkCDjqSyEin0JIYQQErQokCGEEEJI0KJAhhBCCCFBK+RrZLxlNpthNBoD3QwSYrRardthg4QQQuom7AMZnueRn5+P4uLiQDeFhCCVSoXmzZtDq9UGuimEEBKSwj6QEYKY1NRU6PV6mjSP1BthMsbz58+jadOm9NkihBA/COtAxmw2i0FMcnJyoJtDQlBKSgrOnTsHk8mEiIiIQDeHEEJCTlh33gs1MXq9PsAtIaFK6FIym80BbgkhhISmsA5kBJTyJ/5Cny1CCPEvCmQIIYQQErQokCEAgGbNmmHevHle779hwwZwHEejvQghhAQUBTJBhuM4tz+zZs3y6XF37NiBKVOmeL1/v379cP78ecTHx/v0fN6igIkQQog7YT1qKRidP39e/P3bb7/FzJkzcezYMXFbTEyM+DvP8zCbzdBoPP+ZU1JSatUOrVaL9PT0Wt2HEEKCTskZwGIG4hoDajpkKhFlZIJMenq6+BMfHw+O48TrR48eRWxsLFauXIkePXpAp9Nh8+bNOHnyJEaPHo20tDTExMSgV69eWLt2rexx7buWOI7DJ598gptuugl6vR6tW7fG8uXLxdvtMyWLFi1CQkICVq9ejfbt2yMmJgbDhg2TBV4mkwkPP/wwEhISkJycjKeffhoTJkzAmDFjfH4/ioqKcNdddyExMRF6vR7Dhw/H8ePHxdtzc3MxatQoJCYmIjo6Gh07dsSKFSvE+44fPx4pKSmIiopC69atsXDhQp/bQggJQfN7AP/rApSdC3RLiAsUyEjwPI/KGlNAfnier7fX8cwzz+DVV1/FkSNH0KVLF5SXl2PEiBFYt24d9uzZg2HDhmHUqFHIy8tz+zizZ8/Gbbfdhv3792PEiBEYP348CgsLXe5fWVmJN954A19++SX++OMP5OXl4YknnhBvf+211/D1119j4cKF2LJlC0pLS7Fs2bI6vdaJEydi586dWL58ObZu3Qqe5zFixAhxaP3UqVNhMBjwxx9/4MCBA3jttdfErNXzzz+Pw4cPY+XKlThy5AgWLFiARo0a1ak9hJBQYx15WI/f0aR+UZ5MospoRoeZqwPy3IfnDIVeWz9/jjlz5uC6664TryclJaFr167i9RdffBFLly7F8uXLMW3aNJePM3HiRIwbNw4A8Morr+Cdd97B9u3bMWzYMKf7G41GfPDBB2jZsiUAYNq0aZgzZ454+/z58zFjxgzcdNNNAIB3331XzI744vjx41i+fDm2bNmCfv36AQC+/vprZGVlYdmyZbj11luRl5eHm2++GZ07dwYAtGjRQrx/Xl4eunfvjp49ewJgWSlCCJERp1CgQEapKCMTgoQDs6C8vBxPPPEE2rdvj4SEBMTExODIkSMeMzJdunQRf4+OjkZcXBwKCgpc7q/X68UgBgAyMjLE/UtKSnDhwgX07t1bvF2tVqNHjx61em1SR44cgUajQZ8+fcRtycnJaNu2LY4cOQIAePjhh/HSSy+hf//+eOGFF7B//35x3wceeABLlixBt27d8NRTT+HPP//0uS2EkBDFWQ+TlJFRLMrISERFqHF4ztCAPXd9iY6Oll1/4oknsGbNGrzxxhto1aoVoqKicMstt6Cmpsbt49hPqc9xHCwWS632r88uM1/ce++9GDp0KH799Vf89ttvmDt3Lt5880089NBDGD58OHJzc7FixQqsWbMG1157LaZOnYo33ngjoG0mhCiJ0LXk+ruPBBZlZCQ4joNeqwnIjz9ngN2yZQsmTpyIm266CZ07d0Z6ejpOnTrlt+dzJj4+HmlpadixY4e4zWw2Y/fu3T4/Zvv27WEymbBt2zZx2+XLl3Hs2DF06NBB3JaVlYX7778fP/74Ix5//HF8/PHH4m0pKSmYMGECvvrqK8ybNw8fffSRz+0hhIQgmp1b8SgjEwZat26NH3/8EaNGjQLHcXj++efdZlb85aGHHsLcuXPRqlUrtGvXDvPnz0dRUZFXQdyBAwcQGxsrXuc4Dl27dsXo0aMxefJkfPjhh4iNjcUzzzyDxo0bY/To0QCA6dOnY/jw4WjTpg2Kioqwfv16tG/fHgAwc+ZM9OjRAx07doTBYMAvv/wi3kYIIQwV+yodBTJh4K233sLdd9+Nfv36oVGjRnj66adRWlra4O14+umnkZ+fj7vuugtqtRpTpkzB0KFDoVZ77lYbOHCg7LparYbJZMLChQvxyCOP4IYbbkBNTQ0GDhyIFStWiN1cZrMZU6dOxZkzZxAXF4dhw4bh7bffBsDmwpkxYwZOnTqFqKgoDBgwAEuWLKn/Fx5sjNWAsRJQRwC6WM/7ExLKxPMsCmSUiuMDXcTgZ6WlpYiPj0dJSQni4uJkt1VXVyMnJwfNmzdHZGRkgFoYviwWC9q3b4/bbrsNL774YqCb4xdB+Rn7813gt2eBzrcCN38S6NYQElivNQOqioCp24GUtoFuTVhxd/yWoowMaTC5ubn47bffMGjQIBgMBrz77rvIycnBv/71r0A3jUjRKA1CJKhrSemo2Jc0GJVKhUWLFqFXr17o378/Dhw4gLVr11JditKIgQyN0iCE5pFRPsrIkAaTlZWFLVu2BLoZxBMKZAiRoIyM0lFGhhAix9G8GYSIhMCeMjKKRYEMIUSOUumE2FBgr3gUyBBC5KjYlxAJ6lpSOgpkCCFyVCNDiA1lKBWPAhlCiB1KpRNiQxkZpaNAhhAiR11LhNhQhlLxKJAJU4MHD8b06dPF682aNcO8efPc3ofjOCxbtqzOz11fj0P8hL64CbGhriXFo0AmyIwaNQrDhg1zetumTZvAcRz2799f68fdsWMHpkyZUtfmycyaNQvdunVz2H7+/HkMHz68Xp/L3qJFi5CQkODX5whZFMgQIiF0LQW2FcQ1CmSCzD333IM1a9bgzJkzDrctXLgQPXv2RJcuXWr9uCkpKdDr9fXRRI/S09Oh0+ka5LmID2i4KSE2tGik4lEgE2RuuOEGpKSkYNGiRbLt5eXl+P7773HPPffg8uXLGDduHBo3bgy9Xo/OnTvjm2++cfu49l1Lx48fx8CBAxEZGYkOHTpgzZo1Dvd5+umn0aZNG+j1erRo0QLPP/88jEYjAJYRmT17Nvbt2weO48BxnNhm+66lAwcO4JprrkFUVBSSk5MxZcoUlJeXi7dPnDgRY8aMwRtvvIGMjAwkJydj6tSp4nP5Ii8vD6NHj0ZMTAzi4uJw22234cKFC+Lt+/btw9VXX43Y2FjExcWhR48e2LlzJwC2ZtSoUaOQmJiI6OhodOzYEStWrPC5LYpDE4ARYkMZSsWjJQqkeB4wVgbmuSP0kr5Y1zQaDe666y4sWrQIzz77LDjrfb7//nuYzWaMGzcO5eXl6NGjB55++mnExcXh119/xZ133omWLVuid+/eHp/DYrFg7NixSEtLw7Zt21BSUiKrpxHExsZi0aJFyMzMxIEDBzB58mTExsbiqaeewu23346DBw9i1apVWLt2LQAgPj7e4TEqKiowdOhQ9O3bFzt27EBBQQHuvfdeTJs2TRasrV+/HhkZGVi/fj1OnDiB22+/Hd26dcPkyZM9vh5nr08IYjZu3AiTyYSpU6fi9ttvx4YNGwAA48ePR/fu3bFgwQKo1Wrs3bsXERERAICpU6eipqYGf/zxB6Kjo3H48GHExMTUuh2KRV/chEjQqCWlo0BGylgJvJIZmOf+zzlAG+3VrnfffTdef/11bNy4EYMHDwbAupVuvvlmxMfHIz4+Hk888YS4/0MPPYTVq1fju+++8yqQWbt2LY4ePYrVq1cjM5O9H6+88opDXctzzz0n/t6sWTM88cQTWLJkCZ566ilERUUhJiYGGo0G6enpLp9r8eLFqK6uxhdffIHoaPb63333XYwaNQqvvfYa0tLSAACJiYl49913oVar0a5dO4wcORLr1q3zKZBZt24dDhw4gJycHGRlZQEAvvjiC3Ts2BE7duxAr169kJeXhyeffBLt2rUDALRu3Vq8f15eHm6++WZ07twZANCiRYtat0HROPriJkRExb6KR11LQahdu3bo168fPvvsMwDAiRMnsGnTJtxzzz0AALPZjBdffBGdO3dGUlISYmJisHr1auTl5Xn1+EeOHEFWVpYYxABA3759Hfb79ttv0b9/f6SnpyMmJgbPPfec188hfa6uXbuKQQwA9O/fHxaLBceOHRO3dezYEWq1WryekZGBgoKCWj2X9DmzsrLEIAYAOnTogISEBBw5cgQA8Nhjj+Hee+/FkCFD8Oqrr+LkyZPivg8//DBeeukl9O/fHy+88IJPxdXKRjUyhNhQYK90lJGRitCzzEignrsW7rnnHjz00EN47733sHDhQrRs2RKDBg0CALz++uv43//+h3nz5qFz586Ijo7G9OnTUVNTU2/N3bp1K8aPH4/Zs2dj6NChiI+Px5IlS/Dmm2/W23NICd06Ao7jYLH470A7a9Ys/Otf/8Kvv/6KlStX4oUXXsCSJUtw00034d5778XQoUPx66+/4rfffsPcuXPx5ptv4qGHHvJbexoUzSNDiA3VjCkeZWSkOI517wTix4v6GKnbbrsNKpUKixcvxhdffIG7775brJfZsmULRo8ejX//+9/o2rUrWrRogb///tvrx27fvj1Onz6N8+fPi9v++usv2T5//vknsrOz8eyzz6Jnz55o3bo1cnNzZftotVqYzWaPz7Vv3z5UVFSI27Zs2QKVSoW2bdt63ebaEF7f6dOnxW2HDx9GcXExOnToIG5r06YNHn30Ufz2228YO3YsFi5cKN6WlZWF+++/Hz/++CMef/xxfPzxx35pa0BQjQwhNjSKT/EokAlSMTExuP322zFjxgycP38eEydOFG9r3bo11qxZgz///BNHjhzBfffdJxuR48mQIUPQpk0bTJgwAfv27cOmTZvw7LPPyvZp3bo18vLysGTJEpw8eRLvvPMOli5dKtunWbNmyMnJwd69e3Hp0iUYDAaH5xo/fjwiIyMxYcIEHDx4EOvXr8dDDz2EO++8U6yP8ZXZbMbevXtlP0eOHMGQIUPQuXNnjB8/Hrt378b27dtx1113YdCgQejZsyeqqqowbdo0bNiwAbm5udiyZQt27NiB9u3bAwCmT5+O1atXIycnB7t378b69evF20ICBTKESFDXktIFNJD5448/MGrUKGRmZjoMyTUajXj66afFrpHMzEzcddddOHcuQF0/CnTPPfegqKgIQ4cOldWzPPfcc7jiiiswdOhQDB48GOnp6RgzZozXj6tSqbB06VJUVVWhd+/euPfee/Hyyy/L9rnxxhvx6KOPYtq0aejWrRv+/PNPPP/887J9br75ZgwbNgxXX301UlJSnA4B1+v1WL16NQoLC9GrVy/ccsstuPbaa/Huu+/W7s1wory8HN27d5f9jBo1ChzH4aeffkJiYiIGDhyIIUOGoEWLFvj2228BAGq1GpcvX8Zdd92FNm3a4LbbbsPw4cMxe/ZsACxAmjp1Ktq3b49hw4ahTZs2eP/99+vcXsWgM1BCbKjYV/E4ng9cmLly5Ups2bIFPXr0wNixY7F06VLxgFtSUoJbbrkFkydPRteuXVFUVIRHHnkEZrNZnM/DG6WlpYiPj0dJSQni4uJkt1VXVyMnJwfNmzdHZGRkfb40QgAE6Wfs2ErgmzuAxj2Ayb8HujWEBNZ7VwIXjwB3LQdaDAp0a8KKu+O3VECLfYcPH+5yqvr4+HiHSdjeffdd9O7dG3l5eWjatGlDNJGQ8ENdS4TY0P+D4gXVqKWSkhJwHOd2DR2DwSCrxSgtLW2AlhESQuiLmxAb6lpSvKAp9q2ursbTTz+NcePGuU0xzZ07V5wULj4+XjZXCCHEG1QjQ4gNFfsqXVAEMkajEbfddht4nseCBQvc7jtjxgyUlJSIP9IhtoQQL3C02i8hIlo0UvEU37UkBDG5ubn4/fff3WZjAECn09V6ZeUA1juTEBeUny3qWiLEhiaIVDxFZ2SEIOb48eNYu3YtkpOT6/XxhdliKysDtFAkCXnCbMrS5RUUjwIZQiSoa0npApqRKS8vx4kTJ8TrwuRpSUlJyMjIwC233ILdu3fjl19+gdlsRn5+PgAgKSkJWq22zs+vVquRkJAgrtmj1+vF2XEJqSuLxYKLFy9Cr9dDo1F88tOG5pEhxIaKfRUvoN+uO3fuxNVXXy1ef+yxxwAAEyZMwKxZs7B8+XIAQLdu3WT3W79+vbjqc10JKzP7ugAhIe6oVCo0bdo0uAJkWluGEAnKyChdQAOZwYMHu60haIj6Ao7jkJGRgdTUVBiNRr8/HwkvWq0WKpWie3AdUdcSITaUkVG8IMp3+5darQ6uOgZC/IUCGUJs6P9B8YLsVJEQ4n9UI0OIDXUtKR0FMoQQORpuSogNdS0pHgUyhBA5CmQIkaCMjNJRIEMIkaPh14TYUI2M4lEgQwiRo0CGEBvqWlI8CmQIIXI0jwwhEtS1pHQUyBBC5CiVTogNZWQUjwIZQogcBTKE2HCUkVE6CmQIIXaoRoYQGwpklI4CGUKIHA2/JsSGupYUjwIZQogcdS0RIkEZGaWjQIYQIkcZGUJsaDoCxaNAhhAiR1/chNjQdASKR4EMIUSOagIIkaCuJaWjQIYQIkc1MoTYUGCveBTIEELkKJAhRIIyMkpHgQwhxA7VyBAiosBe8SiQIYTI0aglQmyoa0nxKJAhhMjRGSghEtS1pHQUyBBC5CiQIcSGMjKKR4EMIUSOvrgJcUSBvWJRIEMIkeMkXwuUTifhjmrGFI8CGUKInCyQobNQEubEDCVRKgpkCCFy0i9uCmRI2KNiX6WjQIYQYocCGUJEtPaY4lEgQwiRoxoZQmxo0UjFo0CGECJHNTKESFDXktJRIEMIkaNAhhAbmo5A8SiQIYTIUbEvCVfVpcB7VwLv9wXMJutGysgonSbQDSCEKIw0I0NnoSScWEzAxSPsdyGgp5muFY8yMoQQOepaIuFKlnURAhnqWlI6CmQIIXI0aomELcnnXQxgqGtJ6SiQIYTYoRoZEqZ4J4EMZWQUjwIZQoicrNiXvrxJOHH2eacJ8ZSOAhlCiBzHgb68SVgSA3dJMM9R15LSUSBDCHFEIzVIWLIGK5yTQIa6lhSLAhlCiCNaX4aEI2cZGTE72dCNId6iQIYQ4ojWlyFhScjISA6NFNQrHgUyhBBH1LVEwpHweZd1LVFQr3QUyBBCHFEgQ8KR264lCmSUigIZQogTlE4n4YiKfYNRQAOZP/74A6NGjUJmZiY4jsOyZctkt/M8j5kzZyIjIwNRUVEYMmQIjh8/HpjGEhJOxIwMfXmTMEIZmaAU0ECmoqICXbt2xXvvvef09v/+979455138MEHH2Dbtm2Ijo7G0KFDUV1d3cAtJSTMUCBDwpKbjAxlJxUroKtfDx8+HMOHD3d6G8/zmDdvHp577jmMHj0aAPDFF18gLS0Ny5Ytwx133NGQTSUkvNCXNwlHTifEo2JfpVNsjUxOTg7y8/MxZMgQcVt8fDz69OmDrVu3uryfwWBAaWmp7IcQUksUyJCw5CQjQ11LiqfYQCY/Px8AkJaWJtuelpYm3ubM3LlzER8fL/5kZWX5tZ2EhCQatUTCkbslCigjo1iKDWR8NWPGDJSUlIg/p0+fDnSTCAk+lE4n4Yh3MiEejeBTPMUGMunp6QCACxcuyLZfuHBBvM0ZnU6HuLg42Q8hpJYoI0PCkhDISDbRopGKp9hApnnz5khPT8e6devEbaWlpdi2bRv69u0bwJYREg7oLJSEIepaCkoBHbVUXl6OEydOiNdzcnKwd+9eJCUloWnTppg+fTpeeukltG7dGs2bN8fzzz+PzMxMjBkzJnCNJiQcUEaGhCUq9g1GAQ1kdu7ciauvvlq8/thjjwEAJkyYgEWLFuGpp55CRUUFpkyZguLiYlx11VVYtWoVIiMjA9VkQsIDzSNDwpG7jAz9LyhWQAOZwYMHg3fz4eA4DnPmzMGcOXMasFWEEApkSHhyk5GhriXFUmyNDCEkgMTvbupaImHE3YR4FNQrFgUyhBBHVCNDwhItGhmMKJAhhDiieWRIOBICd5pHJqhQIEMIcUQZGRKOqNg3KFEgQwhxgs5CSThy1rVE2Umlo0CGEOKIMjIkHDnLyNA8MopHgQwhxBGN1CBhiYp9gxEFMoQQR5SRIeHIbUaG/heUigIZQogjjr68SThyUyND2UnFokCGEOKIRmqQcCR+3KWBjMONRGEokCGEOKKRGiQcifPIULFvMKFAhhDiiGpkSFhyU+xLgYxiUSBDCHGCamRIGHJX7EvZScWiQIYQ4ogyMiQsUbFvMKJAhhDiiL68SThyt0QBZWQUiwIZQogjysiQsOQkI0PdrIpHgQwhxBEFMiQc0aKRQYkCGUKII5oQj4QlWjQyGFEgQwhxRF/eJByJgTvNIxNMKJAhhDiidDoJR8LnnZMcGqnYV/EokCGEOKIaGRKWqNg3GFEgQwhxgr68SRiiYt+gRIEMIcQRzSNDwhIV+wYjCmQIIY6oa4mEI6dLFNjfRpSGAhlCiCMKZEhYEjIykk00FYHiUSBDCHFEX94kHIlJF2eLRhKlokCGEOKI6gJIOBICd1o0MqhQIEMIcURdSyQs0TwywYgCGUKII+paIuHIabEv/S8oHQUyhBAnaO4MEo6cDb+m/wWlo0CGEOKI6gJIOHI6IR7ViykdBTKEEEdUI0PCkrslCiiQUSoKZAghjiiQIeHI3RIFlJFRLApkCCGOqNiXhCNnw6+p2FfxKJAhhDiiugASlmjRyGBEgQwhxBF1LZFwxDubR4aCeqWjQIYQ4kj48raYA9sOQhoUFfsGIwpkCCGOxIwMBTIkjLgr9qXspGJRIEMIcaTSsEvKyJCw4iwjQ5SOAhlCiCN1BLs0GwPbDkIakrPuI5ocUvEokCGEOFJZAxkLBTIkDDlbooCKfRWLAhlCiCO1tWvJbApsOwhpSGIdDM0jE0wUHciYzWY8//zzaN68OaKiotCyZUu8+OKL4CnFR4h/UUaGhCOeFo0MRppAN8Cd1157DQsWLMDnn3+Ojh07YufOnZg0aRLi4+Px8MMPB7p5hIQuqpEhYcnJPDKgriWlU3Qg8+eff2L06NEYOXIkAKBZs2b45ptvsH379gC3jJAQJ45aoq4lEkbcrX5NGRnFUnTXUr9+/bBu3Tr8/fffAIB9+/Zh8+bNGD58uMv7GAwGlJaWyn4IIbVEgQwJS+66lqhGRqkUnZF55plnUFpainbt2kGtVsNsNuPll1/G+PHjXd5n7ty5mD17dgO2kpAQFCpdS4ZywFQNaCIBXUygW0OUzllGhrqWFE/RGZnvvvsOX3/9NRYvXozdu3fj888/xxtvvIHPP//c5X1mzJiBkpIS8ef06dMN2GJCQkSoFPtufht4vSWwbk6gW0KCAhX7BiNFZ2SefPJJPPPMM7jjjjsAAJ07d0Zubi7mzp2LCRMmOL2PTqeDTqdryGYSEnpCZvi19eBjNgA/TWMHo1HzbBknQqTc1chQRkaxFJ2RqayshEolb6JarYbFQn2VhPhVqGRkhLoGixnY8yWw9ytadoG4JnxeaNHIoKLojMyoUaPw8ssvo2nTpujYsSP27NmDt956C3fffXegm0ZIaBMyFsFe7CscfFSSrzpaCJO4RItGBiNFBzLz58/H888/jwcffBAFBQXIzMzEfffdh5kzZwa6aYSENuHAH+zFvsLBR9qVRAck4oqzCfGo2FfxFB3IxMbGYt68eZg3b16gm0JIeAmV4ddiV4HacRshDpxMiCdmZBq+NcQ7iq6RIYQESKgMvxaoJIEM1cgQV5yufk0ZGaWjQIYQ4ijUin1lNTJ0QCKuuOlaokyeYlEgQwhxFCrDr8ViX+paIl5wOvyaRi0pHQUyhBBHqlAZtSTUyKgka+ZQ1xLxgIp9gwoFMoQQR+oQ61oCJwlkKCNDXJB+XgS0aKTiUSBDCHGkCpGuJekoFGHkEgUyxBVnw69pHhnFo0CGEOJIHH4dIhkZTpKRoVFLxCVaNDIYUSBDCHEUKsOveWlGhrqWiAe8u3lkKJBRKgpkCCGOQm34NcfZRi5RIENccta1RItGKh0FMoQQR8Lw62DvhpEV+1KtA/HA2fBrWjRS8SiQIYQ4UoVI1xKoa4nUBhX7BiMKZAghjkJm+LXkwESjlogn7jIy1LWkWD4FMqdPn8aZM2fE69u3b8f06dPx0Ucf1VvDCCEBJIxa4i2AJYgP/M6KfYO9u4z4j7SmSkCLRiqeT4HMv/71L6xfvx4AkJ+fj+uuuw7bt2/Hs88+izlz5tRrAwkhASBdmyiYszJOZ/YN4sCM+JmbJQooklEsnwKZgwcPonfv3gCA7777Dp06dcKff/6Jr7/+GosWLarP9hFCAkHoWgKCu05GWuxLo5aIJ84mxKNFIxXPp0DGaDRCp9MBANauXYsbb7wRANCuXTucP3++/lpHCAkMlSSQCer1lqjYl9SGu2JfysgolU+BTMeOHfHBBx9g06ZNWLNmDYYNGwYAOHfuHJKTk+u1gYSQAFCHSCAjm9mXzqyJB1TsG5R8CmRee+01fPjhhxg8eDDGjRuHrl27AgCWL18udjkRQoKYdJRPUHct0VpLpDbcTIhHGRnF0njexdHgwYNx6dIllJaWIjExUdw+ZcoU6PX6emscISSA1BGAyUzFviR8iLEKzSMTTHzKyFRVVcFgMIhBTG5uLubNm4djx44hNTW1XhtICAkQcQXsEAhkABp+TbzgptiXupYUy6dAZvTo0fjiiy8AAMXFxejTpw/efPNNjBkzBgsWLKjXBhJCAkRcATuIa2So2JfUhnSUm4CKfRXPp0Bm9+7dGDBgAADghx9+QFpaGnJzc/HFF1/gnXfeqdcGEkICRJzdN4gDGelwWhp+TTxxN/yaMjKK5VMgU1lZidjYWADAb7/9hrFjx0KlUuHKK69Ebm5uvTaQEBIgobDekrOZfXnqWiKuOJsQj4p9lc6nQKZVq1ZYtmwZTp8+jdWrV+P6668HABQUFCAuLq5eG0gICRB1CHQtyYp9qWiTeCANfAX0uVE8nwKZmTNn4oknnkCzZs3Qu3dv9O3bFwDLznTv3r1eG0gICZCQyMhIah7E4dd0Zk1coa6lYOTT8OtbbrkFV111Fc6fPy/OIQMA1157LW666aZ6axwhJIBCYgVsWjSS1IKzCfFo0UjF8ymQAYD09HSkp6eLq2A3adKEJsMjJJSEwqgl2cy+NGqJeOJuQjz63CiVT11LFosFc+bMQXx8PLKzs5GdnY2EhAS8+OKLsFjoj01ISFCHQteSJCNDo5aIJ24zMvS5USqfMjLPPvssPv30U7z66qvo378/AGDz5s2YNWsWqqur8fLLL9drIwkhAaCJZJcmQ2DbURdOZ/alriXigjSDJxBrq+hzo1Q+BTKff/45PvnkE3HVawDo0qULGjdujAcffJACGUJCgVrLLkMhkAF1LRFvOMnICJk8qq1SLJ+6lgoLC9GuXTuH7e3atUNhYWGdG0UIUQAxI1Md2HbUiaTmgQIZ4omzCfEoI6N4PgUyXbt2xbvvvuuw/d1330WXLl3q3ChCiAJodOwymAMZ3kkgQ3V8xCUnQ5OktVU0dF+RfOpa+u9//4uRI0di7dq14hwyW7duxenTp7FixYp6bSAhJECEjIy5JrDtqAunM/tSIENccDohnkp+u2yOGaIEPmVkBg0ahL///hs33XQTiouLUVxcjLFjx+LQoUP48ssv67uNhJBACImMjKTYl0YtEW85G34NUPeSQvk8j0xmZqZDUe++ffvw6aef4qOPPqpzwwghASYGMqFW7EsHI+KCs+HXQgAMsIJfYVoCohg+ZWQIIWEgpIp9qWuJeMNNsS9AQbBCUSBDCHEulDIynHStJQpkiAvSDJ7APiNDFIcCGUKIc6GQkZEV+1oPTnQwIq64G34NUEZGoWpVIzN27Fi3txcXF9elLYQQJREzMsE8asnZzL6UkSGueKqRoc+OEtUqkImPj/d4+1133VWnBhFCFCIkMjLOin1pLhDigtOMDI1aUrpaBTILFy70VzsIIUoTCksUwNmikXQwIq44m0fGGgTzFuqWVCjF18icPXsW//73v5GcnIyoqCh07twZO3fuDHSzCAl9oZSR4UBdS8QzZ8OvAVqmQOF8nkemIRQVFaF///64+uqrsXLlSqSkpOD48eNITEwMdNMICX0hMWrJekk1MsQrTrqWAJbNsxgpI6NQig5kXnvtNWRlZcm6tJo3bx7AFhESRkIqI6OynVXTwYi4QhmZoKTorqXly5ejZ8+euPXWW5Gamoru3bvj448/DnSzCAkPQkbGHMwZGWfFvpSRIS5I5x2SEuqraNSSIik6kPnnn3+wYMECtG7dGqtXr8YDDzyAhx9+GJ9//rnL+xgMBpSWlsp+/OLQMmDVf4CTv/vn8QkJtFDoWoKTeWQokCEuucrI0PIWSqboQMZiseCKK67AK6+8gu7du2PKlCmYPHkyPvjgA5f3mTt3LuLj48WfrKws/zTun/XAX+8BZ6jwmISokOpa4mjRSOKZOPzabruKuiWVTNGBTEZGBjp06CDb1r59e+Tl5bm8z4wZM1BSUiL+nD592j+NE4ammoN4sjBC3AmFjAxPay2R2qAamWCk6GLf/v3749ixY7Jtf//9N7Kzs13eR6fTQafT+btpFMiQ0BdSGRkKZIgXpKPcpOizo2iKzsg8+uij+Ouvv/DKK6/gxIkTWLx4MT766CNMnTo10E2zLeVuNga2HYT4S0hkZKTFvtQ9QDxxM/waoM+OQik6kOnVqxeWLl2Kb775Bp06dcKLL76IefPmYfz48YFumiQjQ4EMCVFiRsYQxNP6U9cS8dLJ34G9X1uvuOpaos+OEim6awkAbrjhBtxwww2BboYja0aGN9c41IUREhKEYB08C9g1Wre7K5K02JcCGeLOlzfZfnfIyFg/O5SRUSRFZ2SUbNXRQgDAsbOXA9wSQvxEyMgAwVsnI9Y8cLaDERVsEo+o2DeYUCDjIwsn1MhQsS8JURpJ0Xyw1sk4LfYN1m4y0mCoRiaoUCDjI7VG6FqiGhkSojgOUAsFv8GakaGZfYkvKCMTTCiQ8ZFKnL6dMjIkhEkLfoOStNiXzqqJlygjE1QokPGRWssCGY4yMiSUCQW+wZ6RoWJfUhs0j0xQoUDGR2rrFzxnoUCGhDAhIxOsC0fSzL7EJ5SRCSYUyPhIE2HNyFAgQ0JZsE+K57TYlw5GxAP7riWqkVE0CmR8pLF2LakokCGhLNiXKZAW+6ooI0O8RRmZYEKBjI80WvYFr+IpkCEhLNgzMjSzL/EFZWSCCgUyPtJaMzJqysiQUBYqGRlpsa+FAhlSS5SRUTQKZHwUIQQyvCnALSHEj4RlCoI1IyNdzZjWyyHecsjIUDZPySiQ8ZGYkaGuJRLKgn0eGRp+TXxCNTLBhAIZH+ki2Re8hjIyJJQFe42M05l96WBEPKCMTFChQMZHWmuxrwYUyJAQFuw1MtJiXxV1LREvOUyIR8W+SkaBjI8idUIgY0aNib4YSYgKlYwMdS2RWqGupWBCgYyPtJHsC14LE6qM9OEmIUoT7ItGSodfWw9OFMgQT1x2LdF3vRJRIOMjoWspAiZU11D3EglRQR/ISGf2Fc6qKZAhnrjKyNBnR4kokPERZ11rScXxqDLQCtgkRIlrLQXpZ9xpsS8djIgd+wCFJsQLKhTI+EoVIf5aXR2kZ6uEeBLsGRma2Zd4w2KfVacamWBCgYyvhInCABgMVQFsCCF+FErzyKjorJq4YB/IUEYmqFAg4yu1LSNTYwjWs1VCPAjm4ddCoS9AGRniHmVkghoFMr7iOBihAQBUVwfp2SohngTzEgUUyBBnyi4Avz4BXDhs2+aQkbGfR4ZGLSkZBTJ1YOZYIGM0BuGXPCHeCOqMjH0Bp7BoJB2MwtrSKcCOj4EPrrJt89S1RKOWFI0CmTowWTMyFmOQjuggxBOx2DcYP+OuMjK8891JeDi7h11KsyueupaoRkbRKJCpAzPH6mTMlJEhoSpUMjI0sy8ROPv7e52RoUBGiSiQqQOha8kUlGerhHghmJcocFkjQwejsOZNIGOPMjKKRoFMHZitc8lYKCNDQlUwzyMjy8jQopHEylkwYp9poYxMUKFApg4s1oyMxR8ZmT/eAN65Asg/UP+PTYi3gjojIw1YqGuJWHmVkbGvkaF1upSMApk6sAgZGX98yf/+IlB4klXWm2ktJxIgvtTIVBX7pSm156Jric6qw5uzYMRslF93OSEeBTJKRIFMHQiBDF/fGZmyfPn1y8fr9/EJ8Za+EbusKgQMZZ73/+MN4LVmwD8b/Nkq7zgU+9LBiMDLYl+7QyN1LSkaBTJ1YFTrAQCqGi++4Gvj3B759YqL9fv4hHgrNg2Iz2Jf/md3e97/3B4AvHyysUBxKPblHLeT8LD9Y+Dd3kDJGReBjH2AQsOvgwkFMnVQrksDAERXWzMolYXA/u/r3hVkf8AoL6jb4xECoNpoxn+WHsD6Y7X8PDXpxS7PbPe8b00Fu/Q0CqQh2Bf70qil8LXiCeDSMWDtLOe30/DroEaBTB1URGUAAGIN1kDmw0HAj/cCe7+u2wNfOGj3RJSRIXX36eYcLN6Wh0kLd9Tujlm92eWZnZ73FQMZo/v9GoIs88LRqCUCVF52vp0mxAtqFMjUQZU1kIkzXGDZmJI8dkPOxro9cMERdpnagV1SIEPqwbliH1dpT23PLgv/8byvsZJdKuLMVdq1FGKjlsoLgAVXAX8tCHRLgourgRkeMzJCoXgIfHZCEAUydVCtZ4FMfE0+cORn2w1Rib4/aE0FUHSK/d58ILukriUSSPFZ7LL4tOf6EsV2LXGhNWpp8zzgwgFg1TOBbklwcTX6jmpkghoFMnVgiM4EACSaLgDn99luqLjk+4NePAaAZ6NFUtpZH48yMiSA4hqzS1MVyzy6I2ZklBDIWIMuIYBRaazbQ+BgJLzPpHZ8zshQjYySUSBTB0ZrIKO3VADn99pucNUP642LR9llansgJpX9ToEMCaSISCCGFbaL3aeu1CgpkLFmZMRAxnowCoV5mYT5fQA6uHoifX+MLrpXHWq6KCMTTCiQqQNVZCwu8vHsytldthvqkpEpOcsuE5sB0dZAppwCGRJg8U3YZckZ1/vwPFBTzn5XQrAgdi1ZD0rWeZ8UEWTVlRCUAXX7vglFR1cAC0fauuiF7k6gFhkZmkcmmFAgUwdajQr7LC0cb6hLBqXcOgIqNh2IYxkflJ61BTiEBIK0TsYVUzXEAltFBAsuupaUMKKqrqSTE5ZfCFw7lGjJOCB3M/D7y+y6NJBxNeeXp7WWaOi+olEgUwdatQp7LK0db6gq9L26XZjVNyYNiG8MZPdn/zy/v+g6LUqIvwkZmVI3AXWNpG5DCYGM2LVkPSipQygjU11s+72CBgOIpMXoQsAqZAkBoLrE+f08Db8WMzI0akmJKJCpgwiNCnv4VrYN6V3YJW8BPrkW2PSm/A4873nUhzBCSahJ6P8Iu9z3DZuZ0pshsITUN2EknvQAas8oOfNVQrDgUOwbQjUy0vWsaFSjjXT0qJBFlAYyrjh0LdndTjUyikaBTB3o1CrssrTBMVUrNufLsLlAZAK78dxuYN0c285l+cAbrYFfHnV8IJMBuGRdT6lckpEBgDZDgVsWsuslecCxlX57PSS01Wlifl0su5Sm6e3JMjIK+MJ3KPYN0YxM+QX2fi9/mE3FH67O7AS+u9N2Xfj7u/vMCrzOyCjgc00cBFUg8+qrr4LjOEyfPj3QTQHAamQM0GJK1BvAg1uBZlcBsRnynYSzwpO/s9qZXQuBfLuZe1c9A7zbkwU+wtlVbJrt9k5jgY5j2e80gokEgjaaXRrcnN1KDxhKqENxKPYNoRoZaUbm8HLg1GZg9+dsKv6cPwLWrIAqzJFfFz6P7j6zAk/Drykjo2hBE8js2LEDH374Ibp06RLopoi0Gvb2GU2SftMON8p3EupapF88uxbK9zn8E7vc9KZtwqaYNPk+0dZViCmQIYEgBDLuzm6V1rUkEDIyQo0Mbwn+Wgdprce53cDq/9iub/uw4dujBPYBqjDXjjddSw7djS6KfSkjo0hBEciUl5dj/Pjx+Pjjj5GYWIdZc+tZhJq9fTVmyZfiFRPkOwkp4LJztm3FdnNxaKLk13XxQITdtugUdulpqKWhnlfiJgQAtELXkruMjFKLfa3XpUOWldA+X1kstkCm30PsUro+28WjQO7W8Fvl237WXiHo9qVrydWEeKGwvEUICopAZurUqRg5ciSGDBkS6KbICBkZgzQjE98YmCSpY6kqYpfCaCRAPlzSYrHVxQiEifCkxEDGTUbmz/nA3CbAl2P9H9AYq1lh3d+/AaXn/ftcpF7U6bgmZmQkgYzZBJzbazuoyjIyCjhzdSj2jbDdFsyBjKEUYsXTVY8Bujj57ZdPAAuHAWueb/CmBZSpRn69NhkZT5+HUFqnKwRpAt0AT5YsWYLdu3djxw7vVuw1GAwwGGyTHpWWlvqradAKGRmT3Yc7ux+Q3Ip9oQhdSrJAxhqMHP0VUOsc/4li0x2fzJtA5tRmdnlyHTsja3O9dy/EF9s/BNbMZL+rdcD0A/K6HhJanHUtbX4LWP8yoI0BJq+XZ2TMCqhDcSj2lXzdBXMgI5wIaaIAfRLQdjiw/1vH/f6cz2rrGl/RsO0LFCEjo41hwYvwefQlI2MfsIj1VUH8uQlhis7InD59Go888gi+/vprREZGer4DgLlz5yI+Pl78ycrK8lv7dBpb1xJvf7orjF4Su5YkWYuKAuDSCWDJv4Cvb3Z8YPv6GEBSI+Oma0k6DLPSz7N9Cit0A4DZAFw84npfEvx0MexSWjh5aBm7rClnS3TUKKxGxr7YVx0iGRmhmLdJT3bZZqjrfX8Lo6yM2ZqREaYK8CYjI9RK2WcQ7QMZtdb6HAoI0IkDRQcyu3btQkFBAa644gpoNBpoNBps3LgR77zzDjQaDcxmx/T1jBkzUFJSIv6cPu1mJtI6EmpkeB4wW+wCGeGfqaqI7SDtfrGYWIGeK04DGWtGxljp+gxD2mVVl/WevFF6Tn69jGYXDWlaayBjrGBf/mUXgIJDtturSxRY7GvXtSSddl4R7fPRyd/ZZcurrZfXut43dzNw4ZDr20OJkJGJSmCXQiDjbiJR4XPgkJGx+z4XgmAKZBRJ0V1L1157LQ4cOCDbNmnSJLRr1w5PP/001Gq1w310Oh10Ol2DtE+okQFYVkajlnxRCv9MVcWsXkX4klfrWAZDulq2PWddNNpolko2VbHuJSHVL7BY5BkZf6+/ImSYYtJZjU+gpkkvOAqc2sS68vTJbFkHfbJjsR6pGyGQAdgB4tQm+e2GUgXPI8PZLlUadtAK1gOS2WjLyAgBTFQC69oTJuIUtBkO/L0S2LsYGPpygze1wQnrKEUlsUvh8+jub20xAdA6BjL2n18xI2NXh0MUQdGBTGxsLDp16iTbFh0djeTkZIftgSALZEwW6LWSG6VdS8JCe5Hx7MB/6Zj7QMZZRobjgJgUNuLp3B62qKRUdbF8+KF9RqbwHzYaKjrZ/YvylpBhyuzOviwDFcj8OBnI3y/fFhkPNB8E3LpIPlKF+C4iCqyLxrow5Bm7mrXqUvmXvBIyHvbFvgAr+LWYlNE+X5zZwd5/fbJtJnHAeR3MFXex/8393wFDZgNqRX/d151D15L15FH8W1s/v1LCbfYjnlx2LVEgo0SK7lpSOo2KE0/2HAp+pRkZYbh1QrZtRJIQyCQ0BTSR8mHbzgIZAOgwhl3+8hhwYp38tjK7kU+Vhbbff5oKvNMd+Ghw/ZwpG8psi69ldmOXgQpkhBVu47Ns3W/VJcCR5cClvwPTJle8WaJCqTjOlpWpqQDOWrtGk1qyy+oSzxPiXToOHFsFHPkFyPtL/hn1B/tiXyD4izaFbqUWVwMqD1/fra8D9I1YTd7Jde73DQVCMKK3y8gI33mRcY73ET4HBrtBIfYT31HXkqIFXYi+YcOGQDdBxHEctGoVDCaLfAg2IK+REQKZxGwWtAC2f5yrHmVBzIVDbGZOwHUgc/V/WEr/3B7gq7FAz7uBIbNYBsI+kJAW+x62rj9SkscOHjEpzh/fbAJ+fZRljfo+aHsN9oRsjC4OSLKu/h2IQMZYbXsf79/E2musAt65gs3b481ohYZw+CfgjzfYgTwiCrhuDtBhNAu0NDpWQBuXwQ64phoWBEQlAtGpng9WDUkXwwLYqmJbFqzFIKDwpPXvIOnOsw8UaiqAj66Wrz6siQQe+BNIbumf9toX+wK2rEQwBjJVRaybCABauamLEagjgM63ANs+YCMk3RUFhwKTXUbGYmSBhxBUR8Y7LhopBDn2s/9SRiaoBF0gozTxUREoKDOguNKIrCTJDUI/beVloDiX/Z6QDWT1AQ58b9svNpN1f0TG27a5CmQiotgcNb89B+z4BNj5GTtIdhtvW51YqAEQupYsFvnBo6LAdSBzbjew+wv2+5/z2dIIve51TFsLk/vFZtgyTIEo9hWCNZXG1pUXEcXWBSqDcgKZja8DF6y1XqYqYMfHwIHvPE8lH5kA3LWMdd8pgVCXdW43O/vVxtraVl1qNyrI7oy25Kztc9i4B6ttMlawzKS/Ahn7Yl/AlpFR6pm12cQ+G0ktgKZX2rbzPPDzdLb6eFILFgh7I7E5u7TPONS3mkqWqY1JDVx9mljsK/kiNlbaglbpd6xAzMjYzbtFNTJBRUGne8EpPZ5lWM6X2FXGx1nXXCo9JwlkmgLtRwFNejnuF9+Ebc++ypYadSYiChj5JjDhF5Y5qbwM/PkOsPIpdrtwYKm4xLqfCv+Rn124m4dGmlUxVQF7vwY+vhr4/Ea2fELeX+ysR0hvJ2bbgq5AZGSE1xKdIv/y1OrZpTBqYfPbwIcDgYM/Nmz7BKXWGqnrrIuIlpyV10glZLPaDU0ky3JFJbGDb3WxYxdiIAmBzMWj7DKpuS2ANJS6H34t/K2SWgKTfwdaXcOu+3N0nVgjI9mm9IUjv74FWPYA8MPd8u0n1wGHl7FA7OZPHIv9BUL3n9DNqrEegO0ni6sPlYWsm/vDgcB/WwBvtnFsd0MSggxdjG1tpJpKW9AqfFalhM+B/RBth4xMmHYtlV8EinKBi38DFX4eCVsHlJGpo/S4SOxHCS6U2hWLxVkzJKVnWfcBwA5YHAfc+C7wfh82gimhKbtNpQbuWcN+9+aMpvkA4IEtwI5PgU1vsH/i5FbA0FeAT69jB8GvxgKNe8rvJ0zGV3SKpVPTJUXTwsGm7Qig/3Rr5uAHIGcj+wHYAVb4J+95t22RzOpi9oFPzPbc9voi/GMJc+wIpLUcAFt7puw88MMkoMVg94FibRjKWRdL076u/2bGKtvszh3GsEkEpd1+T+U4b8/aWSwAU9LaWsIyBcLifDGptrqD6lJAJ/nytw8UhNcsHGD1XsyLVFdOi30V3LVkrAb+Wc9+Lz3LsjNCV1i+NaPXYQzLaLly10/ssyOMUlJbv3vMBpd38dm+b4Cdn8q3/bOh/p/HW0JGRhMJROhZBtBYKamRqUVGxmH4dQNkZMxG4OIxIK2jMkZd7v+ODaYQcCrWgxAZz76zWl4DDHgscO2ToECmjjLEjIx9IJPJLmvKbfUEQtCS2o7VBhir5XUotf3wRjcCBj8NdLmNndmmd2EfNlWErV/47E75fYQD4+ej2Giqe9bYJtaqkBxsmvZhP4OeBk6sBXK3ALl/2s6gWw0B2gxjbW4+iAU6/+sCXDmVpcQzurBgTq1hWaELh9jq4K7qbnwhzchIRUgyMtWl8skIi/PqL5DZMBfY+i5w9bPAoKec7yPMtxOhZ39/YdZRQN4lZk94TdIh9YEmZAEK/2GX0am2g4OhVB4w2J+5in+rRvJLf07c6KzYV8k1MvbvReVl9nn9633gkDWb6GzWb6kmPYGJv9iuCydRJj8EMsJnO6U9cPUM4Lu7Avu+ClkntZZlZWvK2MmMtEbGXm1rZCxGFuTUd6DB88BXN7Pv0fE/sELtQMv9k12qNCw4rCln2WUhw3xqEytrUMCM7hTI1FF6PFvcMd8+kNHqWRdBlTAyg2OpeEFax/prRFJz+WNf/xKw6mnn+1YUsH9aoQD55+nAlA3sC95ZYNCoNfu58gH2zyZ0IcWk2f6Ze91ry9j89R77AdiBLrW97bbYTLaUQX0NA3UVyAhdSzWVwOXj8ttKz9pGWrljsbB9E5zMDH3pBHD0FxbEAGya/oFPOv9yE77s4zLZ7fFNbF0z0Smui3mjrbVHrjIyphoWXEbGs+7EhjiD01uH7hcJGZkU2zo/1aV2SwDY1RiIQbI1gGmQjIyTYl8lZ2Ts/9YVF1lXTYlkkdnaBuH+zCQIJzVdbwcyurHfAxrI2GVkgFrUyHg5aglg76UQINaXv963fU+e2qSMQEb4PA5/jX3Hl55n9ZHVpcCXY9ht0kkwA4gCmTpKj2cfaIeMDMAWkBQCmYQsxxWt/eXK+1mU/P1Ex9sqLsrrWS4cALYtYKvougoMBBzn/Iyw/SjWXVZdws7W87ayEToVBUCOJKNQdo5tE7JV3rp8Elh6H4v+s3pbgzDONvTaISNjzRwYK1g7pErOevecq54Gtn8E3LEYaDfStt1QBrzrJLV/ZieQ1ctxu5ANipXUQkkDGVdi3GRkKguBT4aw0UIAMOINoPdkx/3qm32RuDQjU1PmfgmACruuJTEj489+dxfzyADKrHWwD+qKcuRBDGALJr3lz4yM0F59I2UUUQvdZxqtJJCpYl10gOPimgD7nPK85xoZaeBS34HM+X3A6v/YrtfXgr+VhcChpew1dr619kGw8L8pnHTEZdhqOqMSWZe5Qv6PKJCpo/Q4a0bGvkYGAOIa2/q2G7VpwFbBVqNjr/yiZM4Z6wRR619hoyDsz5q9xXHAFXfKt5lqWIHi5RPscf96n30BVFysfSBzeBmbCMx+EjaBQ42MJCNjP5dMqZeBzPaP2OVvz8sDGWFyQ3unNrFAprqUdaNl9WHZFuH5hNcc19h2H2ernAvcZWTO7LAFMQCw8b8syBNet79E27U3JlV+cBCzj3Bd7Ct8KQoH5IbIyEizVcIEiUqYedie/d86d6vjPrUNZPyakZF8XwhBrBK6ljSRQIR1mgtTta1NuljbvhHR1uU2TPJ9BPYZc+F9BOr/4J1/UH7dfk6w2io5A6x5gc2lJfzd/5wP3PE1kNHV+8ex7w6WUtjaUxTI1FFmAvuHOVdcBYuFh0ol+dKMl3RLJLdu2IYJ/8iCmDSWiam4yJYUAKzDOzkg709gyXhbpsZdpsBbGi1blVdwYi1w4aBvxavSidMiE1hBcdEp25wQaXazPAtnYzUVthXBE5qyTI63gYyg8CSw63OgxwTHtkjlWQ86K59iRZBZVwLtbwC2f8y2CxkZ6VBj+8BASvgbVBWyLwt1BAvMCo7YsjTNB7Gz9uI8NhS/3zSvXxbP8+BqXZNln5FJYX9nTaTjzKguMzJ2NTIVF9nIrJw/2MKTxXnsvfrXd7aFKn3lrNhXPOAq4wtYxiGQ2ey4T1Qtz6r9mpGRnLGL3Yo8CxIDMaO28BlU69hyLoC1a8n6t05qAfS8h2WVd38JlFSwLiRpfcyD24CS045THqjUtoEO9R0UCpkPYZ4b+3XsasNsZIsRC6MiUzuyLHnJaTa67M6lrEjXG/ZZVCkxs6mM4eg0/LqOmiTqodWwSfFOF1XKb+w2zvZ7Q47mAWz/yAIhI1R5yTbnS2w6MPpd9kWUv79+Axl74oHLh64E4cB9zXPAM7nAfX8AD+1hI7TuWePYnywUpR79hXWdaWOA/o+wbd52LUn9/LDtflWuAplt7GBxeju7fvovNt9P6Vn2JS9kdVpJ2uruQK1Psh2AKy6xdPOn1wGfXAMstwYscY1ZbQ4AbJnHAjee96pA2H6NU6/Ydy0JGSV3w1oF9t2WQmam8hIbXbdlHhvxUvgPq/358ibg6AoWAB9f69sswLWd2ddYzUaNmGrYwfjSCfa8PA+c2QVseI0FXf6andk+kHG2jEmtMzLCqCV/ZmSS5fVRgTpLF16jRmfrxjdKsi3qCOCGt1hhvjQzJ9THaGPYQAxX9Sn+ym4JgYxwQlaWzzK7K55kXdb21r3IZmp39l26bwn73EQmAPf+Djz4J3D3Ktvt5/c73scZs5GNRAVs/6tSSsjASVBGpo7UKg6tUmJw+HwpjuWXITtZMr9D4x6sfmHfEqDj2IZtmH1GJrEZ6/6oLpEU7KazDMGE5cDiO2z98f4IZPSSM/DaEu4jzXBFJwN9pzrfX8jIlFhXPu8wxvYlIWxzx2Jx3Ja7xTo6zMkBNTqV1f78/qLtrLBxT5YFik4Buv3LVmCc2t52v5pKh4cSqdS26eVPbQL2f8syWrLnbQR0HcdmDS7OBX6axt6rU5uACT8DzQe6fok8DzVqm5FJdX49KtGW5ROfwNXwa7uuJUHnW4Hs/uzvs+kt4Mx2YMk4+T79Hgauf9H79jot9nVTI/P9RLY2kVrLfoS6CWGxVkGX29nf9/Q2lnXsfIv3bXJHOAPWxsonsZROeVDrGhlhHpl6zsjUVNrmadLbBTKBOriJxb46SddSla0bUdpGaUAr/J2lXU/OqLXsOeo7UJMGMrlb2P/8ni9Z9/b2j4CnT8lHe256g11+dxcbZi8dvHD0V3bZdxrQxFrLl9mNXd/6rvffv0KbOJXzkaZqysiEnLbp7B/g7wtOirR6TwYmr2v4IWr2GRkhIyQdjiy0Ka0jcN9GoNMtQPd/175GxhtCcOTsH+noCuDDQewM2Bl3fbXO2NeKxDcGUtoC4NiB0lPGQjgTkTpunePHWUbmhrfZ5Y5Pbe/trYuAWxcCI/4r/6LhOGDUO2xOoasedd8OoZ/+x8ksM6GJkn8Zx6SyLxQhK3PoR9uq1MLQSRcsvmQVpAGuLt52UBXWFZM9geRgZrHY5tIRukY0WhZgpncGpmxkk7z1nARcOxN4eA/Qewob1iutLft7dS0b7KzY102NzDnr+lHmGnZwE95rUxU7iGV0Y4+1/1tg5ZPAwR+A/7sH+PjaunUHACzLc3YX+10a7GoigU43267XdvqCus4jc3oH61qVfl7KL7KMI8ACQ12cXaG3kwO9xezfeihAUiMj7VqqsgUergIZobhWusK7M/YH74KjwP+6spPAc3sd9zebWHbF2YmRlHBylGL9rPMWefHv2tm236V/h9zNwEeDgK9vY89vrLaNfLJfjkL43/W2uF6saUt2PrJSYTMdU0amHrRJEwKZcg97NiD7jEyC0LXF20bySJdC0CcBt9hNblWfhFW37efKsJjZCKHiPHYgdjYfixB4uKspkYqIll/XN2IHgNQOQMEhVs/ibop3Z//sB75jI6bsMzJthrMJBHVx8iGc7rJaPSbYam7cuXE+m+X11CYgvikw6m1g37esLdLn6DqOFQCf3g5cPMK2uSpKtvKpd0SaDcjoYvuCc3ZwFUaDcBzLLggZBWnQc9vnzp8nqTkw4nXb9YIjwPtXsjPV2hC7liTbXNXIWCy2A+09a2zriPFm1q2oT2I/J38HtvyPHSA5NasvO7sTOP4b0GOi5LlrOdfIn/NthekdbmTZN2MlMPgZ9lxi+2v5lS3WyPhwwDm+FvjaGkRldLUF5F+OsWUHoxux1+lu6D0A/PwIy0z/+//Y+lxSlYXA8odYV3dGN/Z4F4+yAQtdbvN+tI20RsZV15JAGsgI2SpvMjKA7eB9ahOr1Ss6Bfy9inUf65NZ92RVIRvowFuAltcCd7qZVVz4volOYVln+6zxroVs+HN6J+cjmo6vZj+C2Ax2giAlrUnzhlBw7KxbCZAEddS1FDLaWTMyB8+VeNizAdlnZPTJthS5MA+Iqw+pP4gZGbtA5vga25w2zqr1LRZb8ONulI+UfUZG+CfO7ssCmdw/HQMZQxk7q05pK29jemd2ILl8gq2R1chatD3wKfbF0nwQO6A37mGblVUX7xhI+iIhi01uZqxiZ+YcZ6vBkb4utQa48R32+95vgGX3295TGVv04lNGRnoQlc4uKw1kpAEdb2EHeyEbo4nybQoCIYAVhntKD0juCC/RmxqZ6mLb3CEZ3WxdMgDQqJXt95bXyIslvxzLRucJs0jzPPDLo2xG7MxubCbpjjd5Xk8qz5rhiGvMDlo972bZ09h04OD/eXypLmnqkJHZLQk0hf8Ji0XexSmMxuM49rfmzc67XvZ8yS6/uBGYZfc9eehHVs/mTOE/LKvpicVs+/tJa2RMVbagVZaRkdbICF1L3mZkrI8nDTDBu34NHrKjYpY3Kol1nTqbNuPcHvZ9Yx+IZPVhJ6kHf7AG7hybR8w+iHaXEbe3bg5bkgZwvS6fwop9KZCpB12asLk0/rlYgZJKI+L1Xn7R+pNKxc4gxPVHYq2rZEumzK/rqJDaEP6R/l4FfDaM/QMOeJwtgyBwFshUFda+PsB+HRrhuZtdxRbbPLYSGDpXnjJd9iAbrti4B1vqAQCa9AbuXcMK5D4cwM60hOAvNl0eDGX1tgUyrv75fSU9+Cc2k7wuJ4GdMHu000DGxqdiX4D1tedstBVPA64DGbORHTDEbiUfZ3WOSrQdJGszfN9dsa/DzMPWA3VkvDyI8STeOpxeqBfZ+zU7gwbYGfupTax2auSbLEBxRcg2DX/N9vcWPscdx7LPXtM+3rdLIGQReIt8yQNvSM/+hToSabdrj0nyzKI6AjCZnXctReht71HpOfnfsNzNwVWYK8oTaQ2QRscCf4AFG55qZIRJ3ewzufbsMzLC6+kxidXB5W5htUNJzdlJV0IzNueUqYoFuq7WxxLna0lmS89s/5g9lrCt8rLt82G/pl3mFcDwV4Ehs1hAHZ8FtLza8TnEjIz1c242sa7UzCvknwljtS2IiYwHrnzQ/XuhkNF/FMjUg+QYHbKT9ci9XIm9Z4oxqI0fimV9oYmSBzJRCfKiTFf/WP4gDD8GWNdO3lZWUyItapQuJSAQupWikrw/E7f/QhL+iVsPZYWUxbns+Zv1t+1zZDm7PLvLVqsgdIM0ag2AY1/iQvrfPt3dtK/k+fz49xe7CF08jxDIlJxxOwzWp4wMYFvDR0o6aikqwTaFuZD1ELrjfF0aQqVir7U8n30eahvIOJ3Z137mYQ+TQboiDvW3HtRObbHd1nwQ+//L2wr8+jgrxBz3rfNAyV33qUoFXPNs7dolkE3kZqhdICPNOAgZJ+Ggq4sHRs2T7+9uRJg+GSixvkf23SPusgTedoVIh/+rdXYT4rnLyJhsfztP8zC5CmS00exEJqu3fH+et2XBKy46/761mG2BvnCiFi+ZAyy9MxvNV36RTW5XbNftJMw8Ht8YuOIu122XZsRNNayQ/sRaNvJTOmhC+n4/ccJ1UK92cUIQIFTsW0+6ZyUAAPbkFQW2IVLS7g1drOMwWU/FbfUpsztwzfNsLaahr7BtQhAjnD05y8iII6y87FYCnHQtpdi2d7RmUQ4ttd3O8/KzdvF+1ueMiLIFCMKSB/bzeWRLgqLazlVTG9KMjLMMVWwG+8K2GB3eT2nsYj9xaZ1I616ErjfAdkCra0YGsGW5ajXqzYt5ZMoLWKBV10BGOKgJGYsb5rHRgBNX2BZuPfm7rUhW1kzJkPnafM69oZYEMrUduSSdfl4IZMS5RZx89sRsl7Oh7ZIRerIuGdi6jqWfD+G7ydsCYSG44NTsIOtsQjyPGRlPgYxd15IQALnqLuU4z9NOVJdIMs7W7xTppJnCaMvDP7EupzXPy+8vHcnpjpBJNhuA7+5kQQwg/x4EbP8HcY3dZyYVVuxLgUw96d6U/RPuySsObEOkOMnZuDbGcXRJQwYyHAcMfAIYZj0DSJXMnCmM0ii/4HimXJzLLoVAwhvSLyT74YNthrHLnD9s2wySYtQZZ9myBNlXsRFcgpS28uewzy5I/+lrO2lZbcQ3Bm76ELjtC+dfNGoNkGhdd0vo4nDC54yMM9L3N7WD5Emsf0sxkEnw/TmEoNI+te6O05l9JQew6lLgnSuA11uxYlSg9iP2tHaBTFUxuxReq0oF3P6VbX9nxZo15bbh3fUeyGhsgVxtDzrS6QGEriUh6Kjt3CJGScbEPqASgpUUyWitlHbW2y56V5kuBEdCBko2IZ6zYl9JjYyYkfFUI2OfkbE+p7sAyFOR7cbX2GVMuq190hMx4f+pzMWouPjGzrfb0+ptmeq/V9n+D87slHfteTu7u8KW+qBApp50b5oAANh7uhgWnwsQ6pm0/1KokZFqyK4le9JAIKWdda4MM5thePWzwFnrUNgiIZCpxYSC0oMBb5F3r2T3B8ABl47ZJgYUzoa1saxuqN1IYNKvrDhYIJ3pUxtjq6ORun8LG6Ew+j3v2+qLrne4H3U1+Bl2uXme7UzaTv0GMgm231Pa2g6cYkam2LpfXTIy1hF2robOl55zzOj9s4Fduir2Lcqxjqgyu5/8yx37riXhcaTZz7gMVvQLOK6yDNheU0S0f/4nhaxMrTMyTrqW3E2FIL63dgc3npdnZEx2GRnhMVPb2bYJvwv1JZ4INWHC58TZqCXp94BsHhnr49e6a8mLTI67+bMsFta9Dsi7bLWS0VOeulETmrm/XbavJHsz5gPrQp88sE4yvNvbzKR9dirAKJCpJ+3S46DTqFBSZUTOZS/+8RqC9EOmUjt2LXlKpfqTtFskJtV29vz3SjZx02dDWVGuUOxXm5mRdbGsmNjp8ybZhiYKc65403115QO2dYUGPOY8nZzeiQ2zTO/keFtD6nwLC1otRlsgCPmJbb3G2pGSACW5teMBzX4OGV8IXUsn1rI1iErO2l5QyRngvT7A252AbdY1ss7tsa2XJe1Hk3Z/uCsy9ZZ915J9RkYgnO3XOMnI+KtbSaDxsRvAadeSpDDVnspFRsZcA+mIOa8yMgnNbO+t/ZQNzggLsQrZXdmoJSGQcTH82teuJSHQcxcAifO3OHkNhhLb/0j7UbbtXe9gWdVe9zp+JtQ6FlANexW4e7XzLj5XRr/HRltO+Bnocitw3WwAHBtRtts6qszrQIaKfUOSVqNC58bx2JlbhN25RWiZ0oDdNq7Yd9NIv1wjop1PdNRQpF+E+kasEPf4apbRqClns6b+3722lHZtMjIAcNuXbLKyjjc53tZ8IFuSIWcjG0r77Xi23dnK3oKoRFbzcHK96xmFlSSxGZuqvDgXSGPpaWkWhq/PjIz0izypBTtImGvYQcJsso3mqktGpmlfNn9L7hZgobV7MK4Jy0yd2mQbKbX6P2yOm52f2e57bo/td2n3h/Cl3WIwcHYPO7C4CoBdETIo9jUy9icNwhwlzjIyFX4OZHzNyLjrWnKakbFmPMzWAtqaChaA2tfESK+bTbbhx9KJAKOT2XMU57FAR1ob5kyBdf4koUtKzMh4MSGe2LVUy1FLNV4EQNLRQuUXWVAvTHwnFMFrY+RF2VEJbFJIjnMMtke/y77TvB34INWkJ/sRtBjMish/fwlY8QT7vxG7Dj0ESAqb2ZcCmXrUq3kSduYWYes/l3FrTy+LsPzJPlqWfrk25NBrZ6RfhPpkNgtuWT6bb8NsZGvtCBkTwPMXmb3YNDYHizPNB7GsT84frHhOyBh4OpBkdndcTE6pErJZICPJyFj8lZFJaccW44tvwoospSODdnwCFBxm1+sSyLQdDgx7jWVZLCZWUF16BvhL6Mbj2MHLWMmyeVLSDIE0WyQGEGnAI3tZtsdZ4OuOcMCsqWSjQYSAxiEjYz1IOusmEUcs+Wm0my9zyZiN8u+PPV+ybo49X7PrztoqHNxqyoBPrgUKc9j7ah80SwOqvV/bfpfO4hyZwE5wivO8K/C2z8gIAwhqKiFmg1zVyAh/M48ZmTrUyOz63PbZnX6Q1ba4G80n1HUJa64JWcW4xr4FMa5c9Tibvfn4auCLMbag0uuuJZoQL+Rc1aoRFmw4iS0nLvm2unB9s++/lH44A1kfA9hlZJJZe4RJw9QRwL++BX6aaquqr89FN7P7skJoYVZOQamT4d/BSgj8JK9PmoWp1xoZjmOL8QmEg8Tyh+UrODub36I2rryf/QDsIPL3apbtUUWwzExCU+CX6eyL2Vhh+/KPlxSKS4fdSgMIfRKbRba2pF1L4hwrHBueLCV2LbmpkZHOtF2fhAOwdHbfi8dY122f+51P3iitaREIhamAi2Hi1sPJprdtweu5PY6F8sJQaVMNW5AVYFkj6ckNx9VuEreLx9il8FxigCnpynNaI2OW1Mh4ysjYdy15GLUEALGZju24fNwayLjpppO2OamlbbSkt8W93lKpgLEfsiDm/F7bdk+BDE2IF7p6ZCdCq1HhQqkBJy+Wo1Wqhymv/Y2361qSZhyUFsjY00YDYz9mdRX6JMdC5brQxQLZ/eQZH0C+pk2wEwK/YmlGxk+BjD3hS04axNz8ae1GnnkSEQV0HMN+pO5cyjIA5hoWrO74RB5AqSRnksLZZ126dKRdS0J9TGScY7etkAF1NmrJlykGasNZRmb5w2wo+OntwLjFjvdxtaBp4x4sc9LmesfbhOBA+ncvOuX4dxcCGel70X28PNDI6Aocs67aLGRM7Rmr2XNynO1vKQQOQnAhfQ6nNTLGOmRkvOiSajeSvWfC3FSArbvIm0AGYLUyq55mvwuvrz5FJQKTVgKb3wL+eN27Nils+DUFMvUoMkKNXs0SseXEZWw5cTnwgYw9aQ2INsBtk6ZTXU2Upo6Qn+nXp27jbYFM59uAdiPYmkmhwklGRtqd5M84RlaLIPB2vov6wHG2g7eQwRFIayNqu4aXM9KuJVf1MYDt/81ZRsbXOWy8JWZkJIGMMJ/NsV/Zwd5+nSFnGZmOY1kXsMvncdLlUZjDZsiWEgIZochWE2lbePWR/axOI6mF+3WiSs8B83uwbuKbFti2R1oL8jXOAhnJ51Kc+beyFhPi2WUharwIgLR6FiSc3Q1sW8DmgxG6NKVLE7jT6x7gwgH2P1SbWadrQ6sHrnmOZQ7/2cBmGHbH3VD7AKBRS/WsfyuWHt18ws8rvfpCmrp2MeNrg5HO2eCP1bY96XAj63JIaskWKOx4k7zgLtgJI4kkxaUNl5FxFsg0cdwWCNIJ8YQAoi5LSkQ4y8g4yR6KGZkAdC1pnBT7pnex/X5omeN9nAUynoYCO/u7F51yfCxhThlnXTqJ2bZ1vNzV9uRtZY/790rbquiaKNt9hO4yZ/VRgG0EoqHchyUKatG1JLyO7L62bIrw9/Y2I6OOYCOOhGkV/Omq6cBdy2rRzaaMjAwFMvXsKmsg89fJyzCa63P61Hog/YJ1luJuSNLskPCl0pC00cBDu4AHt9ZtojalktaCnN4O/DgF9539D5LARvf4daojZ0GyuxFhDclpjUxdupYkNTLuJv7zptjXb6OWnHQDSKf03/mp4whHZ11LHgMZJxmZohz5c0mfu8ZDAOEskySQrkL/53x2GSn5HrHPknAqeXeftKvPlyUKpHPjeNtNbz87tbeBjBLZB3UBRoFMPeuYGY/kaC3KDCb8edLFtNQN5V/fsaJDYWZRafGxN5NM+VNCU+CWhcCdyxxXam0oGm1oZWGkpKnfdXOA/d+ic8VWJHIsgPVrRsZZF0OgM4ACaY2M0BVUl9FUwtm4xWQryHTWRSR2LdmdQPC8ravB36OWpAGBNFA5twdY9oD8PsJBWiMpBPYYyDj5GxflOnan2QcyrgIB4bmdnfWXSma6FVbjlp6oaewKmO2zRdLia19qZEwGWzG5tyu6i7NTCxmZOq5BFkiuFl8NEApk6plaxWF4Z3b2+cs+F9NKN5Q2Q4GnT8knWxIEOpABgE5j6z6ShTgnLWa0Zgp2Rg/GJZ592dfrPDL26hIY+JvwvhgrJQuq1mEqAmk24fBP7LKZk/oCV11LhlLbgd3f88hIu2iE4OKqx9jl/m+BgqO224WDuzS48lRoKg1gk60LrZoNbPJCKYdAxkUAIQZg1Y63OVuXTRrIaKMhXyzULriWZmS8zaxIsxDS7jJvJxYV/r5Fp4C9i4HcP9n1YAxkFFbsS4GMH4zqwv7hVx3Kh8Fk9rC3n7ma9M5Z0SEJHdLhpdZuxDXxY1EC9gXu164l+8Le0e/78clqSTjYVpfYtnmqjXBHo7W918LK6K2djOhxNfxaGMGijfHfSEKhQFRaNCsciHvdA7S7gf0uzskDW8ZGGsh4OuBKsx4JWbbat6Ic+X5CjYynAMLZsHGBs7WHpF3UKrW8i88+IyPsK13ywlNAIgRWxipb21UR3s/rIryXl4+zDFhVIcuYN+3n3f2VRGEz+1Ig4we9miUhLU6HsmoTNv2tsKLf3lPY5TXPu9+PBDdp6td68KzibClwv45akq7pMvp9NrRWKYT3RahnUWvrPhJEegDM6OZ8rg9XGRl/dysBjhkZs9F2Jh2hB/pOY7/v+9YWWAkH6phUNttxRjc2ksgdabAQm2Griyq0C2TEjIz1vXC1WKPYteSkRsZTRgaQ156oXXQt1SaQkQajwpw6tZmcTppxi05lAeSE5WzyzmCjpq6lkKdScRjZmWVlftkf4O4le8NeBaZuB3pPDnRLiD85WRSvCrZAxq81MtKMjNLS5sLBUQhk6mMFeOkB8MoHne8jPI+pSl5YK2SG/Flwbj+Rm7RbWRsDNL2SjRQyG4A//8eCGSG7FKFna/pM2eC5zkl6UNcns2AGcMzICLU6nqb4FzNJdoEMz9tm8pVyF8g4ZGSEQMY6h48myvOSLcJ9Ki4Cu79gvzsb3eVKXGM2xUOb4cBDO4E7vgYyu3l/fyWhYt/wcENX9k+85vAFVBsD3L0kpVJbVygO8KzDxL+kw4ytZ8CVXAMFMtIJ0JRWLyMcHIURI/URyAiT8mVeweq+nJE+j7R7SSw09eMElfZzfojdIhr2fnAcMMg6tPfP+cAbrdgSHgCrX+E4774vZMObY23DyQv/sT6WJJgDPK9x5GyNqPyDwAdX2a4nt7b9Hmk3+lEWyNhlToS2CNkeTyOWpPeRzgDe5Q7P9xNwHDDuG+BfS+p3gs9AUNjMvhTI+En3rAQ0TohCRY0Zvx8t8HwHQuqTkzk9KmAbyeHfriVpIKOwjIxwcKzt0Fl3hr8GzCwEJv/uuqtBOjpOWvPh7dDfulDZZ2ScBE9trnec2ToiunaTREqDhQi9LSMjEIJaMSMjdC25GrXkpEh5/Su2UUrd75Qvf+CQkZF89uyzSfYTAHozBFq4j9CtpYkCbvrA8/1CkX2WL8AokPETjuMwqivrXvpx91kPexNSz+wDGbUWJtgONP7tWpJMfqe0M0/7Ybn1VWCrUrvPWnCcJB0vOTB7O/S3LhxmpHURQIz9BLj3d+CBrcBzF4EZZ9gU+96SBgvaaMe5g4TuM2GxRY/Dr53M7CsMmR/5JlsJ2m0gI62RsR+1ZB/IeDEpp1gjU2Z7vnDNbEszvgpAgYwf3dKDfaGvP1aAglInQwgJ8ReHeTOi7Wb29eNza6PZlPPXv6y8Qkb7wt6GXHPMWVdJQwYy9l1L9lkglQpo0gNI62AdjVXLw4M0WNDGOGZkYqyBjfD6PY5acpKREe4j1GF1ud12m/2kfu5qZOy7FL2ZXdx+mH6g16sLJBp+HT5apcagR3YizBYeP+6hrAxpQA5f3LENt0QBAPS8G+g3zb/P4Qu13QSI9mfmfn1uJ3UFAe1aqufnlHYtaaMdR281asMuxRoZa2bIVX2Qs2Jfse3Weq+UtrY6maZ95fd3VyMTEcVm+xV4M2rMPvgJ60BGMrGkAlAg42e39WRZme92nvbvJGSESDkZpSFfNDJMP4uBzMg4m2G3QTIydnN+eKpN8ZX0M6eNdhyu3cgacIg1Mj4U+wrdUtLgZ7K1OyxDsn4UYBfI2NXIcJx84VxvAhn7oLchg2CloWLf8DKySyb0WjX+uViBLScCvGQBCR8qlfyMUxstC1782rWkZP6qkfGGs3R8gwQydnN+1Gehs7PnER5bF8smfBMIGZmqIrZQZdl59+0Qi32l75cwZFuyLEBkHOsOsycNTpwtaCkNRLzpWqKMjA1NiBdeYnQa3NaT9ed+sPFkgFtDwopKXrMgDV4s4RrJqBWQkQl415KH+Vt8fh67QAaQZ8CEriZjJfD9BNvoI4/Fvk4yMt68X9KMkLOFJ2sbyGh0zl9jOKIJ8cLPvQOaQ63isPnEJew/Uxzo5pBwIZvXI6bhin2VzH6R0PqYR8ZbAS/2tQtk6r1rya5Gxn5bZILz+3nbtWSx1O79kg6/vnzC8fbGV9h+96ZriePkn5eG/OwoDRX7hp8miXqMtg7FpqwMaTCys0eqkQHgWOzboIGMk7qCBh1+7eeuJelQZOF9Te9s26aLk3d3Clytqq2xG64uXTyytu+XUGAsJZ0jx5vh14A8i0OBDGVkws19g1oCAFYezMc/F2nBRtIA1PJAhmpk4CQjE+Bi30B0LQmBjH29UF1JX5fwvo58E2gzDLjrJ1a3ZZ+V4VRs6n5nhPaZDGwGR9mK01HO72PPVRYIAFpebfs9LsP1flKyjEwYdy2pqGvJa3PnzkWvXr0QGxuL1NRUjBkzBseOHQt0s3zSNj0WQ9qngueBj/74J9DNIeHAbddSmEYyAe1aclfs2xBLFFgPOsIEc/UdyEhfl/BaE7KAf30LtBjMrtsvWRGd4no2ZLGeiWcHTGkA5mndJ4GwIGbmFY63aaOBB7cBUzZ6P3GjdC4Z+3llwklic2DGWeApZfQwKDqQ2bhxI6ZOnYq//voLa9asgdFoxPXXX4+KigrPd1agBwazrMz/7T6D/BKaII/4mbQ+QRMFi8V2NWwDGSUU+57dBXwzDig4IglkvMww+MK+a0noovFnRsbVjLf2gYz9/C5S0qDTbHCcQ8YbAx4DblnIgilnUtvVbuFGqpFhVCoWyNmfGASIkzFpyrFq1SrZ9UWLFiE1NRW7du3CwIEDA9Qq3/XITkLvZknYfqoQ89b+jVdv7uL5ToT4SnrWqtHJgpdwjWPEpQKE7IH9QoP+JARR26zr85zfb7utIbuWhNduP6dOXZmdjAyy5xDIuMmsSOuZTDW+Za9UatcLefpCOropnLuWFEbRGRl7JSVsyfukJIUtRFcLTw5ja4N8u/M09uQVBbg1JKRJu5Y0kbLgJWwzMoA8E9GgM/vaBQ6lZwLUtdQAGRlX7Ltw3BXtqlSSIMzQMNkrT5peafs9nDMyChM0gYzFYsH06dPRv39/dOrUyeV+BoMBpaWlsh8l6dUsCWOvaAyeB2b+dAjmsK26JH4nrT3QaGn4tUAaUOgaMCPjLA3vat2j+mSfkRFqZOwDq7ryJpCxr4e54W33+wvvWeVl4Kep7Hd/vleeNB9s+93ZCCwSEEHzl5g6dSoOHjyIJUuWuN1v7ty5iI+PF3+ysrIaqIXemzG8PWJ1Ghw4W4JvtucFujkkVEkzMmodFfsKZEXQAehakhKyIw05/NpfGZnavobnCoDsvu73Ed6zja8BRad8e576lNzS9nuMwhZEDWNBEchMmzYNv/zyC9avX48mTZq43XfGjBkoKSkRf06fPt1ArfReSqwOj1/Pput+ffUxFFYoY1IhEmJkXUs6WddS2M4jA8hrORpy5Im7wsiGnBDPXzUy1z7PRgeNft/1PtLPnTeFomKB9G7btkB2LXEccN8mYMwHQJOegWsHkVF0IMPzPKZNm4alS5fi999/R/PmzT3eR6fTIS4uTvajRP++MhvtM+JQUmXE7J8PhfeBhfiHXSBDXUtW0rkvGnLUhcuuHM6/B2eHriU/ZWTiMoEp64Hu4+vvMYW/j0WyynJNpfN9G0pGF6DbONcjs0iDU3QgM3XqVHz11VdYvHgxYmNjkZ+fj/z8fFRVOZmlMcho1Cq8NKYT1CoOP+09h8XUxUTqm7QeQa2Tr7UUzoGzN7Uc/uAqkNEn+/eg6NC1ZH399rMcN4SrHmWX3f/t3f5CG8sv2LaVnKnfNpGgp+hAZsGCBSgpKcHgwYORkZEh/nz7rYs5AYJMj+xEPDOsHQDg1RVHcaGU5pYh9YgyMs4FasVeV9kff9daOIxaMrhvjz+ltgOeOQ3c+K53+zvr+iulQIbIKTqQ4Xne6c/EiRMD3bR6c/dVzdE1KwFlBhPm/Hw40M0hocR+HhmLdB6ZcI5kAsRVRiYm1b/P6zCPTAADGYDN3eNtBspZkNfuhvptDwl6ig5kwoFaxeGVm1gX068HzuPrbbmBbhIJFdJZU9Va6loKNFeBQ2y6f59XzMhY60wCmZGpLWkgw6mBYa8Bo94JXHuIIlEgowAdM+Mx/drWAIDnlx3E8n3nAtwiEhLsJsSTdS1ZnOxP/CtQGRn7VbcDWSNTW9Igr/EVwJX3A9HJgWsPUSQKZBRi2jWtcGuPJrDwwMPf7MGT3++D0UxHG1IHavsaGdtVysgEgMtAxs81Mg6jloI0I5PYLGDNIMpGgYxCcByHV8Z2xuQBzaFWcfh+1xlM+WInqo3mQDeNBCuHeWRoraWAkgYO0tWYG6rYFzxgMQe+RqY2pBmZRM/Tb5DwRIGMgkSoVXh2ZAd8dGcPREaosP7YRTzx/T5axoD4hpMU+9LMvo7qex4VT6QZmRaDG64d0mH4xipbrUxDv35fUEaGeIECGQW6tn0aPpvQCxoVh1/2n8cDX+2izAzxgXQWVfti34ZvjWLcsRiIawLcubRhn1eaAUntYPs9vbN/n1da9F1TYfu9vtda8gdpRiahaeDaQRSNAhmF6teqEeaP6w6tRoXfDl/AuI//wt7TxTRslnjPIgl+7Yt9w/lz1G4k8NghILtfwz6vtLg2vgnw2BE23X1itp+fVxrIlNt+D4aMTLSkENrf7xMJWhrPu5BAGd45A0nRWkz+Yif25BVjzHtbMLhtCt68tSuSY4Kgf5sEFi8JZNRaWmsp0KTF1/GN2ZT+cZn+f16Vmq3UzFsAQxnbxqnl7VEqtQa4/WvWbsrIEBcoI6NwfVok4/8e6IfrO6QhQs1hw7GLGPa/Tfhu52k6GBH3pGOsOY5m9g206hLb77EZDfvcQveSkJEJhkJfQfsb2NpGhLhAgUwQaJ0Wi4/u6okVDw9A80bRuFhmwFM/7Me9n+/E0fzSQDePKBUvr6uirqUAi2ts+13a3dMQhOcTamSCKZAhxAMKZIJI67RYrJo+AE8ObQu1isO6owUYNm8T7vtyJ0qqArR+DFEui30g4/x30kCa9ATGfgxMXt/wzy0MxRe6loJhMjxCvESBTJDRadSYenUr/PboQIzsnAGOA1YfuoBR8zfjs805qDCYPD8ICQ92GRn5PDIUyQREl9vYDLUNTRihFIxdS4R4QIFMkGqZEoP3xl+Bn6b2R6MYHfIKKzHnl8Po/9rveOibPSiglbSJm4wMxTFhRuha+vkRdkmBDAkhQVC2Ttzp0iQBG54cjKV7zuLjP/5BXmElft53DjtyCjGySwb0WjVGdslAu/S4QDeVNDRevsQF1ciEM7vVpoVlCggJARTIhIAYnQZ3XpmN23o2wcZjFzF35VHkXKrAp5tzAADvrj+BBwa1xP2DWyIusoGLDEngSDIyPM/LsjBUIxNmSs/IrxfnBqYdhPgBBTIhRKdR4/qO6RjQOgVfb8vFueJq5Fwqx/pjF/H+hpP4ZnseZoxoj1uuaAKVivP8gCS48dJARn4TZWQIIaGCApkQFKVV494BLcTrKw6cx5u/HcPJixV46of9+H7nabw4phN1N4U6SUbGPnChYt8w0/Me4OAPwJgPgJVPA1c+EOgWEVJvKJAJAyM6Z+C6DmlYtOUU3l77N3acKsKweZvQvWkCnhraDn1bJge6icQfeGkgI7+JupbCzA1vAcNeBTRaoN2IQLeGkHpFo5bCRIRahckDW2DtY4MwrCNbiG1PXjHGffwX7vx0G9YfK4CFjm6hpdkAdmm3zhJAXUthSRMEi0QS4gPKyISZzIQofHBnDxSUVePd30/g62152HT8EjYdv4SspCgM65iO23pmoVVqDDiO6miC2uAZbDbZNkOdBDIBahMhhNQzCmTCVGpsJOaM7oTJA1rg8z9P4dsdp3G6sAofb8rBx5ty0CM7EWO6ZeKa9mlonBAV6OYSX2j1wJX3AwAsdhMlUo0MISRUUCAT5rKS9Hjuhg6Yfl0bbD5+EV9szcX2nELsyi3CrtwizPr5MPq3aoT+LZMxonMGspL0gW4y8QF1LRFCQhUFMgQAm4tmWKcMDOuUgdOFlfhmex52nirC9lOF+OPvi/jjbzY/TVZSFHpmJ6FHdiJ6ZCeiTVos1DSUW/Hs5sajriVCSMigQIY4yErS46lh7QAAh8+VYlvOZfx26AK25VzG6cIqnC48i6V7zgIAYnUadM9ORM/sRHRqHIeWKTFokqin4EZhKCNDCAlVFMgQtzpkxqFDZhwm9W+Osmoj9uQVY2duEXbnFmFPXhHKDCYxYyPQaVTIStKjRaNo9G6ehN7Nk6DiOHz1Vy5S4yJxfYc0AECV0YxorQbNGumh19JH0Z8c55EJUEMIIaSe0dGDeC02MgID26RgYJsUAIDJbMHR/DLszmP1NMfyy/DPpQoYTBacKCjHiYJy/Hb4gsPjvLPuuMO2jPhING8ULf60SIlGy5QYNE3Sg+M48DyPyhozonX0kfWFwzwy1LdECAkRdFQgPtOoVejUOB6dGsfjrr7NAABmC48zRZU4U1SFA2dLsD2nELvzilBZY0b7jDjo1CocLyhDhFoFvVaNokojSqqMOF9SjfMl1fjz5GXZc8RHRaB1agzyCitRUGZAgj4C0VoN2qbHIjMhEs0bxSBRH4ErmiYiNU5HmR0X7EcpSeOYr/7KxVtr/ka10YykaC0yE6KQHheJLk3Y37ZjZhxiaY0uQohC0bc+qVdqFYfs5GhkJ0ejf6tGuH9QS3HBQlfrOxVV1OCfSxXIuVSBU9bLfy5V4OTFcpRUGbEzt0jct7jSiOJKI84WVzl9rCaJUeiUGY9GsVqUVZusP0ZwHId26bFolx6HaJ0anRvHo3mj6LCZK8dxZl8eJy+W49WVR7FGkjWrrKnCmSL23i7fd07c3qJRNAtEI1RokqjHFU0T0LlxPHQRasRQlowQEkAcH+ITSpSWliI+Ph4lJSWIi6O1hYJJjcmCo/mlyLlUgdRY1vV0obQaFQYTTl2uxOmiSuRdrkReYSWOF5Sh2mjx/KASsZEaxOg0iIpQQ69TIytRj+zkaGTER6LcYEKTxCi0To1Fk6QoxGg1qKgxwWTmkaCPCLoA6ExRJa56bb1sm1rFwWzhoVZxeOiaVhjbvQlyCytQWFGDM0VV2H+mGAfPlroMGgWZ8ZFIj49Eamwk0uJ0SI2LREqsDqmxOjRJ1CMyQoXU2EgAgFZDk4kTQrzj7fGbTqWIYmk1KnRpkoAuTRLEbenx7IDYr5V8X57nUVplwuHzpTh0rgSlVUbERkYgNlKD2MgIGExmHM0vw7H8MpRWG3HobKmYsREcPFvqVbs0Kg4J+ghkJemRGqtDUrQOjWK0SIrWIjlGh+RoLZKt15P0WqhVHEqqjDhTVIWzxVXQqlXgOLZaeZPEKDSK0SEyQiUGRzzP13ugtPNUkcM2s4XHkPapeGZ4O7RKjQUANE12nCfocrkBB86W4ERBOYxmHscLyrA7twinLlcCAM6VVONcSbXHNqg4IDs5Gon6CGg1KkSoVaiqMaOgzIDMhEgk6rUwWXioOQ5NEqPQNFmPNmmxKK404mK5AR0yYtE2PQ4VBhMiNWrE62vX3VVtNONYfhnS4yORFhcpdrcFW1BKCJGjjAwJS1U1ZpwtrkS10YIqoxmlVUbkXq5E7uUK5JdWIzJCjXPFVdbAx+T5Ad2IjFB5zBZpVBxiIjWI1mpwscyApsl6tE6NgUrFQadWQa9TI1GvRYXBjEvlBlwsM6DKaEas9T6VRjNidGpw4JAap0NVjRlniqoQGaFCgl6L3XlF+Odihew5X7u5M27v1dTn11VtNKPaaMbJi+UoKDWgoMyAgrJq8fcLpdU4XViJGrMFRnP9f80k6iNgMFmQmRCFxglRiFCrEKHmoFGrEKHioFFzuFxeg1OXK3CpvAYVBhNMFiF4YSO3YiM1iIuMgFrFIUanQUykBrE6DWIjNWgUo4PJwqNbVgKSorWIj4pAfBQLjvVaDSLUHNQqDjwPlFq7L41mC5L0bE0jlTXjpeIcgyWLhXfZ1UoCw2S2YMOxizh0rhR/F5RBxXFQc0CCXgu9Vg0VxyExWovWqTFonxGHlFhdoJsc8rw9flMgQ4gH1UYzKgwmccRUUWUNLpfX4HRhJS5V1OByuQGFFWzb5QoDLpfXoLCiBoWVNbJhzo1idGicEAmzdWOlgQUbNebadYnVRbesBOw9XQwAOPbSMOg0ar8/p9nCo6iyBmYLj5MF5SgzmFBjssBotkCrUSE5WodzxVWorDEBHAeLhcfpwkocu1CGfy5WIDVOh2itBrtyi1BlNEPF+T6hX7RWjYoas+cda0EIigRqFQcOQHKMFpfLa6DiWAYvQq1CWbURJgsbgadRcYjSqhEVoYZWo4JWrYJGzSFCrUKCPgIqa/CTHK0Vg6RqowUGE2t/jE6DaJ21e1SrxtmiKkTr1EiPi0K0To2yahPOl1ShosaMDhlx0GvVMFt4mCw8NCrOGvix4E/2u7UtEdb2aO32U6k4GIxmGEwW6LVqGM0WmCw8ItQq7DtdDK1GhbjICERp1dCqVVBbn6ukyogqoxlqjhODO42aQ6RGjcgIlUNgFxmhRrRWDY1aJQbNEWoV8kuqoVZxaJUaA4DVe2lUqlp3W1YbzTAYLdh7phh//XMZP+4+gwulBq//5s0bRSM2MgJRESpkJeoRoVFBo+LQMiUGCfoI1JgsaJsea20bh5TYSKg4ICqCvSae52HhWfsj1MHZ5Wo0W7DvdDE2n7iEW3tm1ftyNtS1REg9iYxQIzLCdsDPiI9CRnwUOjWOd3s/4QBeYTAhNTYSUVrHoMFi4VFpNKPcWpRcWm2CTqPCqcusVsVo5lFebYLJYkFhRQ1iIyOQHK1FSqwOeq0apdUmVNWYEKXVoLTKCAA4X1IFswXo1DgOBpMFRZU14MChbXoM3lj9t/jcDRHEAOzA3iiGnb2mxUX6/Dg8z6PKaEZUBAtGTl2qQGSECmeKqnCxzACThYfJbEGNmV2aLDzioyKQnaxHelwkonUaZMRHoqTKiBqTBSoVh3PFVTBaA8myahPKDSaUV5tQXGVEfkk1DCYL/rEWnQs/lXaBkP2poNkaZdkOijwKyhwPkCYL79C96S+/7j/v9+cIpAg1x7qQjWZrQKGCTqNiARLH4dTlCnDgrF2aLGAqqjQ6PE5ytBaD2qSgabIe0VoNLDyP4iojyqqNsPBAYXkNjheU4eTFClmG8y8Uet1WIYiz8DwiVCoYLRakxUZCr1UDHKC1jui8VF6DtDgdiiuNqDCYEGPNHgrd5bGRGsRFRUCrVuFyhQE6a0B45HwZKmtMSI+LhMHEThbKq03ISGD/AwajBRFqDgaTBQl6Latri41EcowWPM8jRhcBo9kCg8mCGpMFNWbrpcmCGrMZNSYLiiqN+H7naeRcqhBPKlJidRjfJ7tuf0gfUSBDiJ8IB3DhIO6MSujS0GnE+h8AHoMkX/1zsQKHfy3F4LYpfnl8f+I4ThxeH6PTiO+RUN/jrQRr1w8At38bV0xmC6pNFpisXWY8WMDE8+xM/UKJARzHRtglRrPC8KKKGhjNFsRGRiBCzSFap4HJzKOyxoTKGjOM1scymS0wmC0oLK8Bx7GgqNh6wI1Qc9BFqKHTqGDhgcoaFnhVGEyoMLBuRhY8swOfVqNCM2vN05HzZeA41oWpVqlg4XnW5WfNjBnNvPXS9nuN9bpJuG5it5l5HjqNCjqNWnwetYpDWbURWYl6JEVrUVFjRlWNib0mC7tffFQEoiLUsFhHMVp4lh2qNppRZTTLAkILz4sHUoFOo0KN2YKUGB3KDSZZQGk08yisqGFXXGbceKfZz2bJenTLSsCQDmm4vkO6V5md8yVVyLlUgUqDGWUGI84WVcFkYW0+ll+GcoMJBpMF+SVVsPAs+yMErBYeYvQrtCe/1HmNWV5hpe1KicdmBUSiPgL9WjVCdlJ0wNpAXUuEhBGT2YLtpwrRLSuB5twhiicEUjoN63oSCuFNZgsqjWaorN1UBaUGlFYbER8VIQZiBpOFdR+ZLGiWrEeEWiVmGExmHhnxkVCpOMRHNcwcSdVGFmCVVhtZ0AvAYLJAF6HC+WKW/bPwPGpMFlbQrlXjYpkBaXGRSIiKQLnBhNIqI8qqTSittl1WGy1IidHCYLaguMKIZo2ikRytRUFZNeKiImAwWhAZocKFUlZXF6FWwWi2QKdRoajSiItl1SgoY13iHAcxOBW6O7Ua1vWpU6ugixC2qdA6NQY392iCrES93+q9qGuJEOJAo1ahX8tGgW4GIV5htTm260LRtEatQpykrqRZI+UfyoTuaWk3tUCYnoD4JjgrjAghhBBCQIEMIYQQQoIYBTKEEEIICVoUyBBCCCEkaFEgQwghhJCgRYEMIYQQQoJWUAQy7733Hpo1a4bIyEj06dMH27dvD3STCCGEEKIAig9kvv32Wzz22GN44YUXsHv3bnTt2hVDhw5FQUFBoJtGCCGEkABTfCDz1ltvYfLkyZg0aRI6dOiADz74AHq9Hp999lmgm0YIIYSQAFN0IFNTU4Ndu3ZhyJAh4jaVSoUhQ4Zg69atAWwZIYQQQpRA0fM6X7p0CWazGWlpabLtaWlpOHr0qNP7GAwGGAy2lWZLS0v92kZCCCGEBI6iMzK+mDt3LuLj48WfrKysQDeJEEIIIX6i6ECmUaNGUKvVuHDhgmz7hQsXkJ6e7vQ+M2bMQElJifhz+vTphmgqIYQQQgJA0YGMVqtFjx49sG7dOnGbxWLBunXr0LdvX6f30el0iIuLk/0QQgghJDQpukYGAB577DFMmDABPXv2RO/evTFv3jxUVFRg0qRJXt2f53kAVCtDCCGEBBPhuC0cx11RfCBz++234+LFi5g5cyby8/PRrVs3rFq1yqEA2JWysjIAoFoZQgghJAiVlZUhPj7e5e0c7ynUCXIWiwXnzp1DbGwsOI6rt8ctLS1FVlYWTp8+Td1XdUTvZf2g97F+0PtYP+h9rB/h/D7yPI+ysjJkZmZCpXJdCaP4jExdqVQqNGnSxG+PT3U49Yfey/pB72P9oPexftD7WD/C9X10l4kRKLrYlxBCCCHEHQpkCCGEEBK0KJDxkU6nwwsvvACdThfopgQ9ei/rB72P9YPex/pB72P9oPfRs5Av9iWEEEJI6KKMDCGEEEKCFgUyhBBCCAlaFMgQQgghJGhRIEMIIYSQoEWBjI/ee+89NGvWDJGRkejTpw+2b98e6CYpyh9//IFRo0YhMzMTHMdh2bJlstt5nsfMmTORkZGBqKgoDBkyBMePH5ftU1hYiPHjxyMuLg4JCQm45557UF5e3oCvIvDmzp2LXr16ITY2FqmpqRgzZgyOHTsm26e6uhpTp05FcnIyYmJicPPNNzusGJ+Xl4eRI0dCr9cjNTUVTz75JEwmU0O+lIBasGABunTpIk4q1rdvX6xcuVK8nd5D37z66qvgOA7Tp08Xt9F76dmsWbPAcZzsp127duLt9B7WEk9qbcmSJbxWq+U/++wz/tChQ/zkyZP5hIQE/sKFC4FummKsWLGCf/bZZ/kff/yRB8AvXbpUdvurr77Kx8fH88uWLeP37dvH33jjjXzz5s35qqoqcZ9hw4bxXbt25f/66y9+06ZNfKtWrfhx48Y18CsJrKFDh/ILFy7kDx48yO/du5cfMWIE37RpU768vFzc5/777+ezsrL4devW8Tt37uSvvPJKvl+/fuLtJpOJ79SpEz9kyBB+z549/IoVK/hGjRrxM2bMCMRLCojly5fzv/76K//333/zx44d4//zn//wERER/MGDB3mep/fQF9u3b+ebNWvGd+nShX/kkUfE7fReevbCCy/wHTt25M+fPy/+XLx4Ubyd3sPaoUDGB7179+anTp0qXjebzXxmZiY/d+7cALZKuewDGYvFwqenp/Ovv/66uK24uJjX6XT8N998w/M8zx8+fJgHwO/YsUPcZ+XKlTzHcfzZs2cbrO1KU1BQwAPgN27cyPM8e98iIiL477//XtznyJEjPAB+69atPM+zoFKlUvH5+fniPgsWLODj4uJ4g8HQsC9AQRITE/lPPvmE3kMflJWV8a1bt+bXrFnDDxo0SAxk6L30zgsvvMB37drV6W30HtYedS3VUk1NDXbt2oUhQ4aI21QqFYYMGYKtW7cGsGXBIycnB/n5+bL3MD4+Hn369BHfw61btyIhIQE9e/YU9xkyZAhUKhW2bdvW4G1WipKSEgBAUlISAGDXrl0wGo2y97Jdu3Zo2rSp7L3s3LmzbMX4oUOHorS0FIcOHWrA1iuD2WzGkiVLUFFRgb59+9J76IOpU6di5MiRsvcMoM9jbRw/fhyZmZlo0aIFxo8fj7y8PAD0Hvoi5BeNrG+XLl2C2WyWfYAAIC0tDUePHg1Qq4JLfn4+ADh9D4Xb8vPzkZqaKrtdo9EgKSlJ3CfcWCwWTJ8+Hf3790enTp0AsPdJq9UiISFBtq/9e+nsvRZuCxcHDhxA3759UV1djZiYGCxduhQdOnTA3r176T2shSVLlmD37t3YsWOHw230efROnz59sGjRIrRt2xbnz5/H7NmzMWDAABw8eJDeQx9QIENIkJg6dSoOHjyIzZs3B7opQalt27bYu3cvSkpK8MMPP2DChAnYuHFjoJsVVE6fPo1HHnkEa9asQWRkZKCbE7SGDx8u/t6lSxf06dMH2dnZ+O677xAVFRXAlgUn6lqqpUaNGkGtVjtUkF+4cAHp6ekBalVwEd4nd+9heno6CgoKZLebTCYUFhaG5fs8bdo0/PLLL1i/fj2aNGkibk9PT0dNTQ2Ki4tl+9u/l87ea+G2cKHVatGqVSv06NEDc+fORdeuXfG///2P3sNa2LVrFwoKCnDFFVdAo9FAo9Fg48aNeOedd6DRaJCWlkbvpQ8SEhLQpk0bnDhxgj6PPqBAppa0Wi169OiBdevWidssFgvWrVuHvn37BrBlwaN58+ZIT0+XvYelpaXYtm2b+B727dsXxcXF2LVrl7jP77//DovFgj59+jR4mwOF53lMmzYNS5cuxe+//47mzZvLbu/RowciIiJk7+WxY8eQl5cney8PHDggCwzXrFmDuLg4dOjQoWFeiAJZLBYYDAZ6D2vh2muvxYEDB7B3717xp2fPnhg/frz4O72XtVdeXo6TJ08iIyODPo++CHS1cTBasmQJr9Pp+EWLFvGHDx/mp0yZwickJMgqyMNdWVkZv2fPHn7Pnj08AP6tt97i9+zZw+fm5vI8z4ZfJyQk8D/99BO/f/9+fvTo0U6HX3fv3p3ftm0bv3nzZr5169ZhN/z6gQce4OPj4/kNGzbIhmpWVlaK+9x///1806ZN+d9//53fuXMn37dvX75v377i7cJQzeuvv57fu3cvv2rVKj4lJSWshmo+88wz/MaNG/mcnBx+//79/DPPPMNzHMf/9ttvPM/Te1gX0lFLPE/vpTcef/xxfsOGDXxOTg6/ZcsWfsiQIXyjRo34goICnufpPawtCmR8NH/+fL5p06a8Vqvle/fuzf/111+BbpKirF+/ngfg8DNhwgSe59kQ7Oeff55PS0vjdTodf+211/LHjh2TPcbly5f5cePG8TExMXxcXBw/adIkvqysLACvJnCcvYcA+IULF4r7VFVV8Q8++CCfmJjI6/V6/qabbuLPnz8ve5xTp07xw4cP56OiovhGjRrxjz/+OG80Ghv41QTO3XffzWdnZ/NarZZPSUnhr732WjGI4Xl6D+vCPpCh99Kz22+/nc/IyOC1Wi3fuHFj/vbbb+dPnDgh3k7vYe1wPM/zgckFEUIIIYTUDdXIEEIIISRoUSBDCCGEkKBFgQwhhBBCghYFMoQQQggJWhTIEEIIISRoUSBDCCGEkKBFgQwhhBBCghYFMoSQkMdxHJYtWxboZhBC/IACGUKIX02cOBEcxzn8DBs2LNBNI4SEAE2gG0AICX3Dhg3DwoULZdt0Ol2AWkMICSWUkSGE+J1Op0N6errsJzExEQDr9lmwYAGGDx+OqKgotGjRAj/88IPs/gcOHMA111yDqKgoJCcnY8qUKSgvL5ft89lnn6Fjx47Q6XTIyMjAtGnTZLdfunQJN910E/R6PVq3bo3ly5eLtxUVFWH8+PFISUlBVFQUWrdu7RB4EUKUiQIZQkjAPf/887j55puxb98+jB8/HnfccQeOHDkCAKioqMDQoUORmJiIHTt24Pvvv8fatWtlgcqCBQswdepUTJkyBQcOHMDy5cvRqlUr2XPMnj0bt912G/bv348RI0Zg/PjxKCwsFJ//8OHDWLlyJY4cOYIFCxagUaNGDfcGEEJ8F+hVKwkhoW3ChAm8Wq3mo6OjZT8vv/wyz/Nshe/7779fdp8+ffrwDzzwAM/zPP/RRx/xiYmJfHl5uXj7r7/+yqtUKj4/P5/neZ7PzMzkn332WZdtAMA/99xz4vXy8nIeAL9y5Uqe53l+1KhR/KRJk+rnBRNCGhTVyBBC/O7qq6/GggULZNuSkpLE3/v27Su7rW/fvti7dy8A4MiRI+jatSuio6PF2/v37w+LxYJjx46B4zicO3cO1157rds2dOnSRfw9OjoacXFxKCgoAAA88MADuPnmm7F7925cf/31GDNmDPr16+fTayWENCwKZAghfhcdHe3Q1VNfoqKivNovIiJCdp3jOFgsFgDA8OHDkZubixUrVmDNmjW49tprMXXqVLzxxhv13l5CSP2iGhlCSMD99ddfDtfbt28PAGjfvj327duHiooK8fYtW7ZApVKhbdu2iI2NRbNmzbBu3bo6tSElJQUTJkzAV199hXnz5uGjjz6q0+MRQhoGZWQIIX5nMBiQn58v26bRaMSC2u+//x49e/bEVVddha+//hrbt2/Hp59+CgAYP348XnjhBUyYMAGzZs3CxYsX8dBDD+HOO+9EWloaAGDWrFm4//77kZqaiuHDh6OsrAxbtmzBQw895FX7Zs6ciR49eqBjx44wGAz45ZdfxECKEKJsFMgQQvxu1apVyMjIkG1r27Ytjh49CoCNKFqyZAkefPBBZGRk4JtvvkGHDh0AAHq9HqtXr8YjjzyCXr16Qa/X4+abb8Zbb70lPtaECRNQXV2Nt99+G0888QQaNWqEW265xev2abVazJgxA6dOnUJUVBQGDBiAJUuW1MMrJ4T4G8fzPB/oRhBCwhfHcVi6dCnGjBkT6KYQQoIQ1cgQQgghJGhRIEMIIYSQoEU1MoSQgKLebUJIXVBGhhBCCCFBiwIZQgghhAQtCmQIIYQQErQokCGEEEJI0KJAhhBCCCFBiwIZQgghhAQtCmQIIYQQErQokCGEEEJI0KJAhhBCCCFB6/8BNDmqqb0xgnwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "\n",
    "# Check if validation loss is available and plot it\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "encoder_model.save('/media/ahaanbanerjee/Crucial X9/Capstone/Models/SparseAE_comp_wea_mar14.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
